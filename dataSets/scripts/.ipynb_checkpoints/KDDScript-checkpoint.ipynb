{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辅助函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "mape = make_scorer(mean_absolute_percentage_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handleTime(time, title=None):\n",
    "    if title == None:\n",
    "        return pd.DataFrame({\n",
    "            #\"date\": pd.to_datetime(pd.Series([t.date() for t in time])),\n",
    "            \"year\": pd.Series([t.year for t in time]),\n",
    "            \"day_in_month\": pd.Series([t.daysinmonth for t in time]), \n",
    "            \"day_of_year\": pd.Series([t.dayofyear for t in time]),\n",
    "            \"day_of_week\": pd.Series([t.dayofweek for t in time]),\n",
    "            \"hour\": pd.Series([t.hour for t in time]),\n",
    "            \"month\": pd.Series([t.month for t in time]),\n",
    "            \"minute\": pd.Series([t.minute for t in time]),\n",
    "        })\n",
    "    else:\n",
    "        return pd.DataFrame({\n",
    "            #\"date\": pd.to_datetime(pd.Series([t.date() for t in time])),\n",
    "            [title, \"_\", \"year\"]: pd.Series([t.year for t in time]),\n",
    "            [title, \"_\", \"day_in_month\"]: pd.Series([t.daysinmonth for t in time]), \n",
    "            [title, \"_\", \"day_of_year\"]: pd.Series([t.dayofyear for t in time]),\n",
    "            [title, \"_\", \"day_of_week\"]: pd.Series([t.dayofweek for t in time]),\n",
    "            [title, \"_\", \"hour\"]: pd.Series([t.hour for t in time]),\n",
    "            [title, \"_\", \"month\"]: pd.Series([t.month for t in time]),\n",
    "            [title, \"_\", \"minute\"]: pd.Series([t.minute for t in time]),\n",
    "        })   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def displayParam(clf, html = []):\n",
    "    try:\n",
    "        for process in clf.steps:\n",
    "            html += ['<h2>{}</h2>'.format(process[0])]\n",
    "            html += ['<ul>']\n",
    "            for key in process[1].get_params().keys():\n",
    "                html += ['<li>{}__{}</li>'.format(process[0], key)]\n",
    "            html += ['</ul>']\n",
    "    except:\n",
    "        for process in clf.named_regressors:\n",
    "            html += ['<h2>{}</h2>'.format(process)]\n",
    "            html += ['<ul>']\n",
    "            for key in clf.named_regressors[process].get_params().keys():\n",
    "                html += ['<li>{}__{}</li>'.format(process, key)]\n",
    "            html += ['</ul>']\n",
    "      \n",
    "    display(HTML('\\n'.join(html)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    'trajectories': pd.read_csv('../trajectories(table 5)_training.csv'),\n",
    "    'volume': pd.read_csv('../volume(table 6)_training.csv'),\n",
    "    'avg_travel_time': pd.read_csv('../training_20min_avg_travel_time.csv'),\n",
    "    'avg_volume': pd.read_csv('../training_20min_avg_volume.csv'),\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    'trajectories': pd.read_csv('../trajectories(table 5)_training.csv'),\n",
    "    'volume': pd.read_csv('../volume(table 6)_training.csv'),\n",
    "    'avg_travel_time': pd.read_csv('../test1_20min_avg_travel_time.csv'),\n",
    "    'avg_volume': pd.read_csv('../test1_20min_avg_volume.csv'),\n",
    "}\n",
    "\n",
    "links = pd.read_csv('../links (table 3).csv')\n",
    "routes = pd.read_csv('../routes (table 4).csv')\n",
    "weather = pd.concat([\n",
    "    pd.read_csv('../weather (table 7)_training_update.csv'),\n",
    "    pd.read_csv('../weather (table 7)_test1.csv')])\n",
    "\n",
    "train_trajectories = train_data['trajectories']\n",
    "train_volume = train_data['volume']\n",
    "\n",
    "train_avg_travel_time = train_data['avg_travel_time']\n",
    "train_avg_volume = train_data['avg_volume']\n",
    "\n",
    "test_avg_travel_time = test_data['avg_travel_time']\n",
    "test_avg_volume = test_data['avg_volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  整理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 处理天气数据 插值填充每小时数据\n",
    "\n",
    "weather.date = pd.to_datetime(weather.date)\n",
    "weather['time'] = weather.date + pd.to_timedelta(weather.hour, unit='h')\n",
    "\n",
    "weather = weather.set_index(['time'])\n",
    "weather = weather.reindex(pd.date_range(start= weather.date.min(), end=weather.date.max(), freq='1H'), fill_value='NaN')\n",
    "\n",
    "weather['date'] = pd.to_datetime([t.date() for t in weather.index])\n",
    "weather['year'] = [t.year for t in weather.index]\n",
    "weather['day_of_year'] = [t.dayofyear for t in weather.index]\n",
    "weather['hour'] = [t.hour for t in weather.index]\n",
    "for col in ['pressure', 'sea_pressure', 'wind_direction', 'wind_speed', 'temperature', 'rel_humidity', 'precipitation']:\n",
    "    weather[col] = weather[col].astype(float).interpolate()\n",
    "    \n",
    "weather = weather.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 拆分时间窗\n",
    "\n",
    "def split_time_window(time_window):\n",
    "    time_start = [time[1:-1].split(',')[0] for time in time_window]\n",
    "    time_end = [time[1:-1].split(',')[1] for time in time_window]\n",
    "\n",
    "    return pd.to_datetime(pd.Series(time_start)), pd.to_datetime(pd.Series(time_end))\n",
    "\n",
    "train_avg_volume['time_start'], train_avg_volume['time_end'] = split_time_window(train_avg_volume.time_window)\n",
    "train_avg_volume = train_avg_volume.drop(['time_window'], axis=1)\n",
    "\n",
    "train_avg_travel_time['time_start'], train_avg_travel_time['time_end'] = split_time_window(train_avg_travel_time.time_window)\n",
    "train_avg_travel_time = train_avg_travel_time.drop(['time_window'], axis=1)\n",
    "\n",
    "test_avg_volume['time_start'], test_avg_volume['time_end'] = split_time_window(test_avg_volume.time_window)\n",
    "test_avg_volume = test_avg_volume.drop(['time_window'], axis=1)\n",
    "\n",
    "test_avg_travel_time['time_start'], test_avg_travel_time['time_end'] = split_time_window(test_avg_travel_time.time_window)\n",
    "test_avg_travel_time = test_avg_travel_time.drop(['time_window'], axis=1)\n",
    "\n",
    "ind = (train_avg_travel_time.time_start < '2016-10-8')\n",
    "ind &= (train_avg_travel_time.time_start > '2016-9-28')\n",
    "train_avg_travel_time = train_avg_travel_time[~ind]\n",
    "\n",
    "ind = (train_avg_volume.time_start < '2016-10-8')\n",
    "ind &= (train_avg_volume.time_start > '2016-9-28')\n",
    "train_avg_volume = train_avg_volume[~ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ld = preprocessing.LabelBinarizer()\n",
    "\n",
    "class TimeProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column = None, title = None):\n",
    "        self.column = column\n",
    "        self.title = title\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        table = posts.join(handleTime(posts[self.column], self.title))\n",
    "        return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DropProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns = None):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return posts.drop(self.columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "    \n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 天气特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WeatherFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, weather):\n",
    "        self.weather = weather\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        table = posts.merge(self.weather, how=\"left\", on=['year','day_of_year','hour'])\n",
    "        table.fillna(-1, inplace=True)\n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 前两小时特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LastTwoHour(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def before(self, table, delta, col = 'avg_travel_time'):\n",
    "        result = []\n",
    "        time = table.time_start - pd.to_timedelta(delta, unit='m')\n",
    "        for i in range(len(time)):\n",
    "            ind = table.tollgate_id == table.tollgate_id[i]\n",
    "            ind &= table.intersection_id == table.intersection_id[i]\n",
    "            ind &= table.time_start == time[i]\n",
    "\n",
    "            assert(len(table[ind]) < 2)\n",
    "            if(len(table[ind]) == 0):\n",
    "                result.append(None)\n",
    "            else:\n",
    "                result.append(table[col][ind].values[0])\n",
    "        return pd.Series(result)\n",
    "    \n",
    "    def fit(self,x,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, posts):\n",
    "        return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_process = [\n",
    "    ('weather', WeatherFeatures(weather)),\n",
    "    #('last2hour', LastTwoHour()),\n",
    "]\n",
    "combined_features = FeatureUnion(feature_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "feature_selector = SelectKBest(k='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('transformed_time', TimeProcessor('time_start')),\n",
    "    ('encoding',MultiColumnLabelEncoder(columns=['intersection_id'])),\n",
    "    ('drop', DropProcessor(['time_start', 'time_end'])),\n",
    "    ('combined_features', combined_features),\n",
    "    ('feature_select', feature_selector),\n",
    "]\n",
    "\n",
    "preprocess = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "lr = LinearRegression()\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    #RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    #ExtraTreesRegressor(),\n",
    "    #XGBRegressor(),\n",
    "    #SVR()\n",
    "]\n",
    "\n",
    "stack = StackingRegressor(regressors=regressors,meta_regressor=lr,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>预处理参数</h1>\n",
       "<h2>transformed_time</h2>\n",
       "<ul>\n",
       "<li>transformed_time__column</li>\n",
       "<li>transformed_time__title</li>\n",
       "</ul>\n",
       "<h2>encoding</h2>\n",
       "<ul>\n",
       "<li>encoding__columns</li>\n",
       "</ul>\n",
       "<h2>drop</h2>\n",
       "<ul>\n",
       "<li>drop__columns</li>\n",
       "</ul>\n",
       "<h2>combined_features</h2>\n",
       "<ul>\n",
       "<li>combined_features__n_jobs</li>\n",
       "<li>combined_features__transformer_list</li>\n",
       "<li>combined_features__transformer_weights</li>\n",
       "<li>combined_features__weather</li>\n",
       "<li>combined_features__weather__weather</li>\n",
       "</ul>\n",
       "<h2>feature_select</h2>\n",
       "<ul>\n",
       "<li>feature_select__k</li>\n",
       "<li>feature_select__score_func</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayParam(preprocess, ['<h1>预处理参数</h1>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>训练参数</h1>\n",
       "<h2>linearregression</h2>\n",
       "<ul>\n",
       "<li>linearregression__copy_X</li>\n",
       "<li>linearregression__fit_intercept</li>\n",
       "<li>linearregression__n_jobs</li>\n",
       "<li>linearregression__normalize</li>\n",
       "</ul>\n",
       "<h2>gradientboostingregressor</h2>\n",
       "<ul>\n",
       "<li>gradientboostingregressor__alpha</li>\n",
       "<li>gradientboostingregressor__criterion</li>\n",
       "<li>gradientboostingregressor__init</li>\n",
       "<li>gradientboostingregressor__learning_rate</li>\n",
       "<li>gradientboostingregressor__loss</li>\n",
       "<li>gradientboostingregressor__max_depth</li>\n",
       "<li>gradientboostingregressor__max_features</li>\n",
       "<li>gradientboostingregressor__max_leaf_nodes</li>\n",
       "<li>gradientboostingregressor__min_impurity_split</li>\n",
       "<li>gradientboostingregressor__min_samples_leaf</li>\n",
       "<li>gradientboostingregressor__min_samples_split</li>\n",
       "<li>gradientboostingregressor__min_weight_fraction_leaf</li>\n",
       "<li>gradientboostingregressor__n_estimators</li>\n",
       "<li>gradientboostingregressor__presort</li>\n",
       "<li>gradientboostingregressor__random_state</li>\n",
       "<li>gradientboostingregressor__subsample</li>\n",
       "<li>gradientboostingregressor__verbose</li>\n",
       "<li>gradientboostingregressor__warm_start</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayParam(stack, ['<h1>训练参数</h1>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "prep_params = {\n",
    "    'encoding__columns':['intersection_id'],\n",
    "    #'feature_select__k': 15\n",
    "}\n",
    "\n",
    "stack_params = {\n",
    "    #model\n",
    "    'gradientboostingregressor__n_estimators':sp_randint(20, 300)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess.set_params(**prep_params)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_search = RandomizedSearchCV(\n",
    "    estimator=stack,\n",
    "    param_distributions=stack_params, \n",
    "    scoring=mape, \n",
    "    n_iter=4,\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = pd.Series([t.hour for t in train_avg_travel_time.time_start])\n",
    "ind = ((t < 10) & (t > 8)) | ((t > 17) & (t < 19))\n",
    "\n",
    "train_x=train_avg_travel_time.drop(['avg_travel_time'], axis=1)\n",
    "train_y=train_avg_travel_time.avg_travel_time\n",
    "\n",
    "train_x=preprocess.fit_transform(train_x, train_y)\n",
    "group=train_x[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: linearregression (1/2)\n",
      "Fitting regressor2: gradientboostingregressor (2/2)\n"
     ]
    }
   ],
   "source": [
    "clf = param_search.fit(train_x, train_y, groups=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.39360075,  0.85779271,  0.42220235,  0.5492012 ]),\n",
       " 'mean_score_time': array([ 0.00290389,  0.00509543,  0.00280223,  0.003298  ]),\n",
       " 'mean_test_score': array([-0.39883488, -0.43914388, -0.40455015, -0.42120258]),\n",
       " 'mean_train_score': array([-0.26381718, -0.26068091, -0.26338203, -0.26224393]),\n",
       " 'param_gradientboostingregressor__n_estimators': masked_array(data = [40 95 44 60],\n",
       "              mask = [False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'gradientboostingregressor__n_estimators': 40},\n",
       "  {'gradientboostingregressor__n_estimators': 95},\n",
       "  {'gradientboostingregressor__n_estimators': 44},\n",
       "  {'gradientboostingregressor__n_estimators': 60}),\n",
       " 'rank_test_score': array([1, 4, 2, 3]),\n",
       " 'split0_test_score': array([-0.28976999, -0.28986692, -0.29167501, -0.28742358]),\n",
       " 'split0_train_score': array([-0.25737463, -0.25599004, -0.25720082, -0.25689438]),\n",
       " 'split1_test_score': array([-0.44047373, -0.47513032, -0.44695718, -0.46058221]),\n",
       " 'split1_train_score': array([-0.2682488 , -0.26507425, -0.2679041 , -0.26687703]),\n",
       " 'split2_test_score': array([-0.23648832, -0.2406505 , -0.23685918, -0.23732625]),\n",
       " 'split2_train_score': array([-0.27037097, -0.26676216, -0.26988209, -0.26841345]),\n",
       " 'split3_test_score': array([-0.37973289, -0.36725868, -0.38655464, -0.37535227]),\n",
       " 'split3_train_score': array([-0.25684134, -0.25270828, -0.25615397, -0.25459644]),\n",
       " 'split4_test_score': array([-0.64770946, -0.82281299, -0.66070473, -0.7453286 ]),\n",
       " 'split4_train_score': array([-0.26625013, -0.26286985, -0.26576918, -0.26443834]),\n",
       " 'std_fit_time': array([ 0.00366601,  0.03019913,  0.01761338,  0.01261919]),\n",
       " 'std_score_time': array([ 0.00073217,  0.00101883,  0.00080661,  0.00040091]),\n",
       " 'std_test_score': array([ 0.14303062,  0.20753203,  0.14737599,  0.17911896]),\n",
       " 'std_train_score': array([ 0.00563346,  0.00541556,  0.0056365 ,  0.00550356])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradientboostingregressor__n_estimators': 40}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4741775f0eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mparam_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     print('* {}: train:{}, test:{}'.format(i,\n\u001b[1;32m      8\u001b[0m         \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\mlxtend\\regressor\\stacking_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_name_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mmeta_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_meta_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[0;32m--> 524\u001b[0;31m                         dtype=None)\n\u001b[0m\u001b[1;32m    525\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "param_search.best_estimator_.verbose=0\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "i = 0\n",
    "for train, test in gkf.split(train_x, train_y, groups=group):\n",
    "    param_search.best_estimator_.fit(train_x[train], train_y[train])\n",
    "    print('* {}: train:{}, test:{}'.format(i,\n",
    "        mean_absolute_percentage_error(train_y[train], param_search.best_estimator_.predict(train_x[train])),\n",
    "        mean_absolute_percentage_error(train_y[test], param_search.best_estimator_.predict(train_x[test]))))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('best_estimator', param_search.best_estimator_)\n",
    "])\n",
    "joblib.dump(pipe, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def before(table, delta, col = 'avg_travel_time'):\n",
    "    result = []\n",
    "    time = table.time_start - pd.to_timedelta(delta, unit='m')\n",
    "    for i in range(len(time)):\n",
    "        ind = table.tollgate_id == table.tollgate_id[i]\n",
    "        ind &= table.intersection_id == table.intersection_id[i]\n",
    "        ind &= table.time_start == time[i]\n",
    "        \n",
    "        assert(len(table[ind]) < 2)\n",
    "        if(len(table[ind]) == 0):\n",
    "            result.append(None)\n",
    "        else:\n",
    "            result.append(table[col][ind].values[0])\n",
    "    return pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../submission_sample_travelTime.csv').drop('avg_travel_time', axis = 1)\n",
    "test_x = pd.read_csv('../submission_sample_travelTime.csv').drop('avg_travel_time', axis = 1)\n",
    "test_x['time_start'], test_x['time_end'] = split_time_window(test_x.time_window)\n",
    "test_x = test_x.drop(['time_window'], axis=1)\n",
    "\n",
    "test_x = preprocess.transform(test_x)\n",
    "\n",
    "clf = param_search.best_estimator_.fit(train_x, train_y)\n",
    "submission['avg_travel_time'] =  clf.predict(test_x)\n",
    "submission.to_csv('avg_travel_time.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9330995855ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparam_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\mlxtend\\regressor\\stacking_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_name_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mmeta_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_meta_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[0;32m--> 524\u001b[0;31m                         dtype=None)\n\u001b[0m\u001b[1;32m    525\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hsyec\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "param_search.best_estimator_.fit(train_x[train], train_y[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
