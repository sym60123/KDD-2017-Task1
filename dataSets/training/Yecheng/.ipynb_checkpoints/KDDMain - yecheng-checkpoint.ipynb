{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import dill\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辅助函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Tools import *\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "mape = make_scorer(mean_absolute_percentage_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dill.load_session(\"data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Preprocess.TimeProcessor import *\n",
    "from Preprocess.Utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 天气特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WeatherFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, weather):\n",
    "        self.weather = weather\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        table = posts.merge(self.weather,  how='left' ,on=['year','day_of_year','hour'])\n",
    "        return table.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 前两小时特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LastTwoHour(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.info1 = pd.concat([\n",
    "            pd.read_csv('travel_time_feature.csv'), \n",
    "            pd.read_csv('test_travel_time_feature.csv')]).fillna(0)\n",
    "        \n",
    "        self.info2 = pd.concat([\n",
    "            pd.read_csv('../train_volume_feature.csv'), \n",
    "            pd.read_csv('../test_volume_feature.csv')\n",
    "        ]).fillna(0)\n",
    "    \n",
    "    def fit(self,x,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, posts):\n",
    "        table = posts.merge(self.info1, how='left' ,on=['day_of_year']).fillna(-1)\n",
    "        table = table.merge(self.info2, how='left' ,on=['day_of_year']).fillna(0)\n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "feature_selector = SelectKBest(k=all)\n",
    "\n",
    "from sklearn.feature_selection import GenericUnivariateSelect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "def log(x):\n",
    "    return np.log(x)\n",
    "\n",
    "#TODO: 0.65*abs(x) * log(abs(x) + 1)\n",
    "def obj1(y_true, y_pred):\n",
    "    x = y_true - y_pred\n",
    "    absx = np.abs(x)\n",
    "    \n",
    "    grad =((x*abs(x)+x)*log(abs(x)+1)+x*abs(x))/(abs(x)+x**2)\n",
    "    hess =(2*abs(x)+x**2)/(x**2*abs(x)+abs(x)+2*x**2)\n",
    "    return grad, hess\n",
    "\n",
    "def obj2(y_true, y_pred):\n",
    "    tmp = y_true -  y_pred\n",
    "    hess = 2 / y_true    \n",
    "    grad = - hess *  tmp\n",
    "       \n",
    "    return grad, hess\n",
    "\n",
    "'''\n",
    "    sig = np.sign(y_true - y_pred)\n",
    "    grad = sig#(sig *  (-1 / y_true)) * 10\n",
    "    hess = np.zeros(len(y_true))\n",
    "    return grad, hess\n",
    "'''\n",
    "xgb = XGBRegressor(objective=obj2)\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    #RandomForestRegressor(),\n",
    "    #LGBMRegressor(objective= obj2),\n",
    "    #BaggingRegressor(),\n",
    "    LGBMRegressor(boosting_type='dart', objective= obj2),\n",
    "    XGBRegressor(objective=obj2),\n",
    "    SVR(),\n",
    "]\n",
    "\n",
    "stack = StackingRegressor(regressors=regressors, meta_regressor=xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# displayParam(preprocess, ['<h1>预处理参数</h1>'])\n",
    "# displayParam(stack, ['<h1>训练参数</h1>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2016-07-19 00:00:00\n",
       "1       2016-07-19 00:20:00\n",
       "2       2016-07-19 01:40:00\n",
       "3       2016-07-19 02:00:00\n",
       "4       2016-07-19 02:40:00\n",
       "5       2016-07-19 03:40:00\n",
       "6       2016-07-19 04:00:00\n",
       "7       2016-07-19 04:20:00\n",
       "8       2016-07-19 04:40:00\n",
       "9       2016-07-19 05:00:00\n",
       "10      2016-07-19 06:00:00\n",
       "11      2016-07-19 06:20:00\n",
       "12      2016-07-19 06:40:00\n",
       "13      2016-07-19 07:00:00\n",
       "14      2016-07-19 07:20:00\n",
       "15      2016-07-19 07:40:00\n",
       "16      2016-07-19 08:00:00\n",
       "17      2016-07-19 08:20:00\n",
       "18      2016-07-19 08:40:00\n",
       "19      2016-07-19 09:00:00\n",
       "20      2016-07-19 09:20:00\n",
       "21      2016-07-19 09:40:00\n",
       "22      2016-07-19 10:00:00\n",
       "23      2016-07-19 10:20:00\n",
       "24      2016-07-19 10:40:00\n",
       "25      2016-07-19 11:00:00\n",
       "26      2016-07-19 11:20:00\n",
       "27      2016-07-19 11:40:00\n",
       "28      2016-07-19 12:00:00\n",
       "29      2016-07-19 12:20:00\n",
       "                ...        \n",
       "25114   2016-10-16 21:00:00\n",
       "25115   2016-10-16 22:20:00\n",
       "25116   2016-10-16 23:00:00\n",
       "25117   2016-10-17 00:20:00\n",
       "25118   2016-10-17 08:40:00\n",
       "25119   2016-10-17 09:40:00\n",
       "25120   2016-10-17 10:00:00\n",
       "25121   2016-10-17 10:40:00\n",
       "25122   2016-10-17 12:00:00\n",
       "25123   2016-10-17 12:20:00\n",
       "25124   2016-10-17 12:40:00\n",
       "25125   2016-10-17 13:20:00\n",
       "25126   2016-10-17 13:40:00\n",
       "25127   2016-10-17 14:20:00\n",
       "25128   2016-10-17 14:40:00\n",
       "25129   2016-10-17 15:00:00\n",
       "25130   2016-10-17 16:00:00\n",
       "25131   2016-10-17 16:20:00\n",
       "25132   2016-10-17 16:40:00\n",
       "25133   2016-10-17 17:20:00\n",
       "25134   2016-10-17 18:00:00\n",
       "25135   2016-10-17 18:40:00\n",
       "25136   2016-10-17 19:00:00\n",
       "25137   2016-10-17 19:40:00\n",
       "25138   2016-10-17 20:00:00\n",
       "25139   2016-10-17 20:40:00\n",
       "25140   2016-10-17 21:00:00\n",
       "25141   2016-10-17 21:20:00\n",
       "25142   2016-10-17 22:20:00\n",
       "25143   2016-10-17 22:40:00\n",
       "Name: time_start, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_avg_travel_time.time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-19 08:00:00</td>\n",
       "      <td>2016-07-19 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-19 08:20:00</td>\n",
       "      <td>2016-07-19 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-19 08:40:00</td>\n",
       "      <td>2016-07-19 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-19 09:00:00</td>\n",
       "      <td>2016-07-19 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-19 09:20:00</td>\n",
       "      <td>2016-07-19 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-19 09:40:00</td>\n",
       "      <td>2016-07-19 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-20 08:00:00</td>\n",
       "      <td>2016-07-20 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-20 08:20:00</td>\n",
       "      <td>2016-07-20 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-20 08:40:00</td>\n",
       "      <td>2016-07-20 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-20 09:00:00</td>\n",
       "      <td>2016-07-20 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-20 09:20:00</td>\n",
       "      <td>2016-07-20 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-20 09:40:00</td>\n",
       "      <td>2016-07-20 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-21 08:00:00</td>\n",
       "      <td>2016-07-21 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-22 08:00:00</td>\n",
       "      <td>2016-07-22 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-22 08:20:00</td>\n",
       "      <td>2016-07-22 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-22 08:40:00</td>\n",
       "      <td>2016-07-22 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-22 09:00:00</td>\n",
       "      <td>2016-07-22 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-22 09:20:00</td>\n",
       "      <td>2016-07-22 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-22 09:40:00</td>\n",
       "      <td>2016-07-22 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-23 08:00:00</td>\n",
       "      <td>2016-07-23 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-23 08:20:00</td>\n",
       "      <td>2016-07-23 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-23 08:40:00</td>\n",
       "      <td>2016-07-23 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-23 09:00:00</td>\n",
       "      <td>2016-07-23 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-23 09:20:00</td>\n",
       "      <td>2016-07-23 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-24 08:00:00</td>\n",
       "      <td>2016-07-24 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-24 08:20:00</td>\n",
       "      <td>2016-07-24 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-24 08:40:00</td>\n",
       "      <td>2016-07-24 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-24 09:00:00</td>\n",
       "      <td>2016-07-24 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-24 09:20:00</td>\n",
       "      <td>2016-07-24 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-24 09:40:00</td>\n",
       "      <td>2016-07-24 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-08 09:20:00</td>\n",
       "      <td>2016-10-08 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-08 09:40:00</td>\n",
       "      <td>2016-10-08 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-09 08:00:00</td>\n",
       "      <td>2016-10-09 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-09 08:20:00</td>\n",
       "      <td>2016-10-09 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-09 09:20:00</td>\n",
       "      <td>2016-10-09 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-09 09:40:00</td>\n",
       "      <td>2016-10-09 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-10 09:00:00</td>\n",
       "      <td>2016-10-10 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-10 09:20:00</td>\n",
       "      <td>2016-10-10 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-10 09:40:00</td>\n",
       "      <td>2016-10-10 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-11 08:20:00</td>\n",
       "      <td>2016-10-11 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-11 08:40:00</td>\n",
       "      <td>2016-10-11 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-11 09:20:00</td>\n",
       "      <td>2016-10-11 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-11 09:40:00</td>\n",
       "      <td>2016-10-11 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-12 08:00:00</td>\n",
       "      <td>2016-10-12 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-12 08:40:00</td>\n",
       "      <td>2016-10-12 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-12 09:00:00</td>\n",
       "      <td>2016-10-12 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-12 09:40:00</td>\n",
       "      <td>2016-10-12 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-13 08:00:00</td>\n",
       "      <td>2016-10-13 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-13 08:20:00</td>\n",
       "      <td>2016-10-13 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-13 09:40:00</td>\n",
       "      <td>2016-10-13 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-14 09:40:00</td>\n",
       "      <td>2016-10-14 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-15 08:40:00</td>\n",
       "      <td>2016-10-15 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-15 09:00:00</td>\n",
       "      <td>2016-10-15 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-15 09:20:00</td>\n",
       "      <td>2016-10-15 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-15 09:40:00</td>\n",
       "      <td>2016-10-15 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-16 08:40:00</td>\n",
       "      <td>2016-10-16 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-16 09:20:00</td>\n",
       "      <td>2016-10-16 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-16 09:40:00</td>\n",
       "      <td>2016-10-16 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-17 08:40:00</td>\n",
       "      <td>2016-10-17 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-17 09:40:00</td>\n",
       "      <td>2016-10-17 10:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2404 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     intersection_id  tollgate_id          time_start            time_end\n",
       "0                  B            3 2016-07-19 08:00:00 2016-07-19 08:20:00\n",
       "1                  B            3 2016-07-19 08:20:00 2016-07-19 08:40:00\n",
       "2                  B            3 2016-07-19 08:40:00 2016-07-19 09:00:00\n",
       "3                  B            3 2016-07-19 09:00:00 2016-07-19 09:20:00\n",
       "4                  B            3 2016-07-19 09:20:00 2016-07-19 09:40:00\n",
       "5                  B            3 2016-07-19 09:40:00 2016-07-19 10:00:00\n",
       "6                  B            3 2016-07-20 08:00:00 2016-07-20 08:20:00\n",
       "7                  B            3 2016-07-20 08:20:00 2016-07-20 08:40:00\n",
       "8                  B            3 2016-07-20 08:40:00 2016-07-20 09:00:00\n",
       "9                  B            3 2016-07-20 09:00:00 2016-07-20 09:20:00\n",
       "10                 B            3 2016-07-20 09:20:00 2016-07-20 09:40:00\n",
       "11                 B            3 2016-07-20 09:40:00 2016-07-20 10:00:00\n",
       "12                 B            3 2016-07-21 08:00:00 2016-07-21 08:20:00\n",
       "13                 B            3 2016-07-22 08:00:00 2016-07-22 08:20:00\n",
       "14                 B            3 2016-07-22 08:20:00 2016-07-22 08:40:00\n",
       "15                 B            3 2016-07-22 08:40:00 2016-07-22 09:00:00\n",
       "16                 B            3 2016-07-22 09:00:00 2016-07-22 09:20:00\n",
       "17                 B            3 2016-07-22 09:20:00 2016-07-22 09:40:00\n",
       "18                 B            3 2016-07-22 09:40:00 2016-07-22 10:00:00\n",
       "19                 B            3 2016-07-23 08:00:00 2016-07-23 08:20:00\n",
       "20                 B            3 2016-07-23 08:20:00 2016-07-23 08:40:00\n",
       "21                 B            3 2016-07-23 08:40:00 2016-07-23 09:00:00\n",
       "22                 B            3 2016-07-23 09:00:00 2016-07-23 09:20:00\n",
       "23                 B            3 2016-07-23 09:20:00 2016-07-23 09:40:00\n",
       "24                 B            3 2016-07-24 08:00:00 2016-07-24 08:20:00\n",
       "25                 B            3 2016-07-24 08:20:00 2016-07-24 08:40:00\n",
       "26                 B            3 2016-07-24 08:40:00 2016-07-24 09:00:00\n",
       "27                 B            3 2016-07-24 09:00:00 2016-07-24 09:20:00\n",
       "28                 B            3 2016-07-24 09:20:00 2016-07-24 09:40:00\n",
       "29                 B            3 2016-07-24 09:40:00 2016-07-24 10:00:00\n",
       "...              ...          ...                 ...                 ...\n",
       "2374               C            3 2016-10-08 09:20:00 2016-10-08 09:40:00\n",
       "2375               C            3 2016-10-08 09:40:00 2016-10-08 10:00:00\n",
       "2376               C            3 2016-10-09 08:00:00 2016-10-09 08:20:00\n",
       "2377               C            3 2016-10-09 08:20:00 2016-10-09 08:40:00\n",
       "2378               C            3 2016-10-09 09:20:00 2016-10-09 09:40:00\n",
       "2379               C            3 2016-10-09 09:40:00 2016-10-09 10:00:00\n",
       "2380               C            3 2016-10-10 09:00:00 2016-10-10 09:20:00\n",
       "2381               C            3 2016-10-10 09:20:00 2016-10-10 09:40:00\n",
       "2382               C            3 2016-10-10 09:40:00 2016-10-10 10:00:00\n",
       "2383               C            3 2016-10-11 08:20:00 2016-10-11 08:40:00\n",
       "2384               C            3 2016-10-11 08:40:00 2016-10-11 09:00:00\n",
       "2385               C            3 2016-10-11 09:20:00 2016-10-11 09:40:00\n",
       "2386               C            3 2016-10-11 09:40:00 2016-10-11 10:00:00\n",
       "2387               C            3 2016-10-12 08:00:00 2016-10-12 08:20:00\n",
       "2388               C            3 2016-10-12 08:40:00 2016-10-12 09:00:00\n",
       "2389               C            3 2016-10-12 09:00:00 2016-10-12 09:20:00\n",
       "2390               C            3 2016-10-12 09:40:00 2016-10-12 10:00:00\n",
       "2391               C            3 2016-10-13 08:00:00 2016-10-13 08:20:00\n",
       "2392               C            3 2016-10-13 08:20:00 2016-10-13 08:40:00\n",
       "2393               C            3 2016-10-13 09:40:00 2016-10-13 10:00:00\n",
       "2394               C            3 2016-10-14 09:40:00 2016-10-14 10:00:00\n",
       "2395               C            3 2016-10-15 08:40:00 2016-10-15 09:00:00\n",
       "2396               C            3 2016-10-15 09:00:00 2016-10-15 09:20:00\n",
       "2397               C            3 2016-10-15 09:20:00 2016-10-15 09:40:00\n",
       "2398               C            3 2016-10-15 09:40:00 2016-10-15 10:00:00\n",
       "2399               C            3 2016-10-16 08:40:00 2016-10-16 09:00:00\n",
       "2400               C            3 2016-10-16 09:20:00 2016-10-16 09:40:00\n",
       "2401               C            3 2016-10-16 09:40:00 2016-10-16 10:00:00\n",
       "2402               C            3 2016-10-17 08:40:00 2016-10-17 09:00:00\n",
       "2403               C            3 2016-10-17 09:40:00 2016-10-17 10:00:00\n",
       "\n",
       "[2404 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = (train_avg_travel_time.time_start < '2016-10-8') & (train_avg_travel_time.time_start > '2016-9-30')\n",
    "#t = t | (train_avg_travel_time.time_start < '2016-9-1')\n",
    "#trafic_train = pd.read_csv('../trafic_train.csv')\n",
    "tt = train_avg_travel_time.time_start.apply(lambda x: (x.hour < 10) & (x.hour >= 8))\n",
    "t = (~t) & tt\n",
    "#t=tt\n",
    "t2 = train_avg_travel_time[t]\n",
    "train_x=t2.drop(['avg_travel_time'], axis=1)\n",
    "train_y=t2.avg_travel_time\n",
    "\n",
    "train_x.index = range(len(train_x))\n",
    "train_y.index = range(len(train_y))\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2404, 4)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "stack_params = {\n",
    "    #model\n",
    "    'lgbmregressor__n_estimators': sp_randint(300, 500),\n",
    "    #'xgbregressor__n_estimators': [300, 400, 500],\n",
    "    #'lgbmregressor-2__n_estimators': [300,400,500],\n",
    "}\n",
    "\n",
    "param_search = RandomizedSearchCV(\n",
    "    estimator=stack,\n",
    "    param_distributions=stack_params, \n",
    "    scoring=mape, \n",
    "    n_iter=4,\n",
    "    cv=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.479724962373\n",
      "{'lgbmregressor__n_estimators': 363}\n",
      "* 0: train:0.18558186484451794, test:0.24351458748629815\n",
      "* 1: train:0.17398303838528195, test:0.23625352462220428\n",
      "* 2: train:0.18301744924772412, test:0.24924196616880942\n",
      "ALL: 0.18371980789640097 \n",
      " test ALL： 0.24300335942577064\n"
     ]
    }
   ],
   "source": [
    "prep_params = {\n",
    "    'encoding__columns':['intersection_id'],\n",
    "    'feature_select__k':  'all'\n",
    "}\n",
    "\n",
    "feature_process = [\n",
    "    ('weather', WeatherFeatures(weather)),\n",
    "  #  ('last2hour', LastTwoHour()),\n",
    "]\n",
    "\n",
    "estimators = [\n",
    "    ('transformed_time', TimeProcessor('time_start')),\n",
    "    ('encoding',MultiColumnLabelEncoder(columns=['intersection_id'])),\n",
    "    ('drop', DropProcessor(['time_start', 'time_end'])),\n",
    "    ('save_table', Saver('../Before.pickle')),\n",
    "    ('combined_features', FeatureUnion(feature_process)),\n",
    "    ('feature_select', feature_selector),\n",
    "]\n",
    "\n",
    "preprocess = Pipeline(estimators)\n",
    "preprocess.set_params(**prep_params)\n",
    "\n",
    "train_x=preprocess.fit_transform(train_x, train_y)\n",
    "group=train_x[:,4]\n",
    "\n",
    "clf = param_search.fit(train_x, train_y, groups=group)\n",
    "param_search.cv_results_\n",
    "param_search.best_params_\n",
    "\n",
    "param_search.best_estimator_.verbose=0\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "i = 0\n",
    "clf2 = param_search.best_estimator_\n",
    "\n",
    "print(param_search.best_score_)\n",
    "print(param_search.best_params_)\n",
    "a={0:[],1:[],2:[]}\n",
    "for train, test in gkf.split(train_x, train_y, groups=group):\n",
    "    clf2.fit(train_x[train], train_y[train])\n",
    "    print('* {}: train:{}, test:{}'.format(i,\n",
    "        mean_absolute_percentage_error(train_y[train],  clf2.predict(train_x[train])),\n",
    "        mean_absolute_percentage_error(train_y[test],  clf2.predict(train_x[test]))))\n",
    "    a[i]= mean_absolute_percentage_error(train_y[test],  clf2.predict(train_x[test]))\n",
    "    i+=1\n",
    "    \n",
    "clf2.fit(train_x, train_y)\n",
    "print('ALL:', mean_absolute_percentage_error(train_y,  clf2.predict(train_x)),\n",
    "     '\\n','test ALL：',(a[0]+a[1]+a[2])/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.externals import joblib\\nfrom sklearn.pipeline import make_pipeline\\npipe = Pipeline([\\n    ('preprocess', preprocess),\\n    ('best_estimator', param_search.best_estimator_)\\n])\\njoblib.dump(pipe, 'model.pkl')\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.externals import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('best_estimator', param_search.best_estimator_)\n",
    "])\n",
    "joblib.dump(pipe, 'model.pkl')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../submission_sample_travelTime.csv').drop('avg_travel_time', axis = 1)\n",
    "test_x = pd.read_csv('../submission_sample_travelTime.csv').drop('avg_travel_time', axis = 1)\n",
    "test_x['time_start'], test_x['time_end'] = split_time_window(test_x.time_window)\n",
    "test_x = test_x.drop(['time_window'], axis=1)\n",
    "\n",
    "test_x = preprocess.transform(test_x)\n",
    "\n",
    "clf = param_search.best_estimator_.fit(train_x, train_y)\n",
    "submission['avg_travel_time'] =  clf.predict(test_x)\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "submission.to_csv('time{}.{}.{}.csv'.format(\n",
    "    str(now.date()),\n",
    "    str(now.hour),\n",
    "    str(now.minute)\n",
    "), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.218864897012\n",
      "{'lgbmregressor__n_estimators': 386}\n",
      "* 0: train:0.1155416042845095, test:0.16700947412091863\n",
      "* 1: train:0.11139846190030658, test:0.15497675730306343\n",
      "* 2: train:0.10072806365069632, test:0.24363375204898205\n",
      "* 3: train:0.1036005840129719, test:0.18046532519717998\n"
     ]
    }
   ],
   "source": [
    "feature_process = [\n",
    "    ('weather', WeatherFeatures(weather)),\n",
    "    ('last2hour', LastTwoHour()),\n",
    "]\n",
    "combined_features = FeatureUnion(feature_process)\n",
    "\n",
    "estimators = [\n",
    "    ('transformed_time', TimeProcessor('time_start')),\n",
    "    #('encoding',MultiColumnLabelEncoder(columns=['intersection_id'])),\n",
    "    ('drop', DropProcessor(['time_start', 'time_end'])),\n",
    "    ('save_table', Saver('../VolumeBefore.pickle')),\n",
    "    ('combined_features', combined_features),\n",
    "    ('feature_select', feature_selector),\n",
    "]\n",
    "\n",
    "preprocess = Pipeline(estimators)\n",
    "\n",
    "t = (train_avg_volume.time_start < '2016-10-8') & (train_avg_volume.time_start > '2016-10-1')\n",
    "t = t | (train_avg_volume.time_start < '2016-9-1')\n",
    "tt = train_avg_volume.time_start.apply(lambda x: (x.hour < 10) & (x.hour >= 8))\n",
    "t = (~t) & tt\n",
    "t = train_avg_volume[t]\n",
    "train_x = t.drop(['volume'], axis=1)\n",
    "train_y = t.volume\n",
    "\n",
    "train_x.index = range(len(train_x))\n",
    "train_y.index = range(len(train_y))\n",
    "\n",
    "train_x = preprocess.transform(train_x)\n",
    "\n",
    "group=train_x[:,4]\n",
    "\n",
    "param_search = RandomizedSearchCV(\n",
    "    estimator=stack,\n",
    "    param_distributions=stack_params, \n",
    "    scoring=mape, \n",
    "    n_iter=4,\n",
    "    cv=2\n",
    ")\n",
    "\n",
    "clf = param_search.fit(train_x, train_y, groups=group)\n",
    "print(param_search.best_score_)\n",
    "print(param_search.best_params_)\n",
    "\n",
    "param_search.best_estimator_.verbose=0\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "i = 0\n",
    "clf = param_search.best_estimator_\n",
    "\n",
    "for train, test in gkf.split(train_x, train_y, groups=group):\n",
    "    clf.fit(train_x[train], train_y[train])\n",
    "    print('* {}: train:{}, test:{}'.format(i,\n",
    "        mean_absolute_percentage_error(train_y[train],  clf.predict(train_x[train])),\n",
    "        mean_absolute_percentage_error(train_y[test],  clf.predict(train_x[test]))))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10635953804442032\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('../submission_sample_volume.csv').drop('volume', axis = 1)\n",
    "test_x = pd.read_csv('../submission_sample_volume.csv').drop('volume', axis = 1)\n",
    "test_x['time_start'], test_x['time_end'] = split_time_window(test_x.time_window)\n",
    "test_x = test_x.drop(['time_window'], axis=1)\n",
    "\n",
    "test_x = preprocess.transform(test_x)\n",
    "\n",
    "clf = param_search.best_estimator_.fit(train_x, train_y)\n",
    "print(mean_absolute_percentage_error(train_y,  clf.predict(train_x)))\n",
    "submission['volume'] =  clf.predict(test_x)\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "submission.to_csv('volume{}.{}.{}.csv'.format(\n",
    "    str(now.date()),\n",
    "    str(now.hour),\n",
    "    str(now.minute)\n",
    "), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
