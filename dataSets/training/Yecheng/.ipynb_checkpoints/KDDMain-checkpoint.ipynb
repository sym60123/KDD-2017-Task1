{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import dill\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辅助函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Tools import *\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "mape = make_scorer(mean_absolute_percentage_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dill.load_session(\"data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Preprocess.TimeProcessor import *\n",
    "from Preprocess.Utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 天气特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WeatherFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, weather):\n",
    "        self.weather = weather\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        table = posts.merge(self.weather,  how='left' ,on=['year','day_of_year','hour'])\n",
    "        return table.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 前两小时特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LastTwoHour(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.info1 = pd.concat([\n",
    "            pd.read_csv('travel_time_feature.csv'), \n",
    "            pd.read_csv('test_travel_time_feature.csv')]).fillna(0)\n",
    "        \n",
    "        self.info2 = pd.concat([\n",
    "            pd.read_csv('../train_volume_feature.csv'), \n",
    "            pd.read_csv('../test_volume_feature.csv')\n",
    "        ]).fillna(0)\n",
    "    \n",
    "    def fit(self,x,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, posts):\n",
    "        table = posts.merge(self.info1, how='left' ,on=['day_of_year']).fillna(-1)\n",
    "        table = table.merge(self.info2, how='left' ,on=['day_of_year']).fillna(0)\n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "feature_selector = SelectKBest(k=all)\n",
    "\n",
    "from sklearn.feature_selection import GenericUnivariateSelect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "def log(x):\n",
    "    return np.log(x)\n",
    "\n",
    "#TODO: 0.65*abs(x) * log(abs(x) + 1)\n",
    "def obj1(y_true, y_pred):\n",
    "    x = y_true - y_pred\n",
    "    absx = np.abs(x)\n",
    "    \n",
    "    grad =((x*abs(x)+x)*log(abs(x)+1)+x*abs(x))/(abs(x)+x**2)\n",
    "    hess =(2*abs(x)+x**2)/(x**2*abs(x)+abs(x)+2*x**2)\n",
    "    return grad, hess\n",
    "\n",
    "def obj2(y_true, y_pred):\n",
    "    tmp = y_true -  y_pred\n",
    "    hess = 2 / y_true    \n",
    "    grad = - hess *  tmp\n",
    "       \n",
    "    return grad, hess\n",
    "\n",
    "'''\n",
    "    sig = np.sign(y_true - y_pred)\n",
    "    grad = sig#(sig *  (-1 / y_true)) * 10\n",
    "    hess = np.zeros(len(y_true))\n",
    "    return grad, hess\n",
    "'''\n",
    "xgb = XGBRegressor(objective=obj2)\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    #RandomForestRegressor(),\n",
    "    #LGBMRegressor(objective= obj2),\n",
    "    #BaggingRegressor(),\n",
    "    LGBMRegressor(boosting_type='dart', objective= obj2),\n",
    "    XGBRegressor(objective=obj2),\n",
    "    SVR(),\n",
    "]\n",
    "\n",
    "stack = StackingRegressor(regressors=regressors, meta_regressor=xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# displayParam(preprocess, ['<h1>预处理参数</h1>'])\n",
    "# displayParam(stack, ['<h1>训练参数</h1>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "stack_params = {\n",
    "    #model\n",
    "    'lgbmregressor__n_estimators': sp_randint(300, 500),\n",
    "    #'xgbregressor__n_estimators': [300, 400, 500],\n",
    "    #'lgbmregressor-2__n_estimators': [300,400,500],\n",
    "}\n",
    "\n",
    "param_search = RandomizedSearchCV(\n",
    "    estimator=stack,\n",
    "    param_distributions=stack_params, \n",
    "    scoring=mape, \n",
    "    n_iter=4,\n",
    "    cv=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yecheng/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [ 8 24] are constant.\n",
      "  UserWarning)\n",
      "/home/yecheng/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.486991840125\n",
      "{'lgbmregressor__n_estimators': 422}\n",
      "* 0: train:0.08823511974520051, test:0.2723711787036266\n",
      "* 1: train:0.09757830125753647, test:0.2645813381668182\n",
      "* 2: train:0.09815207427114547, test:0.26967396708935537\n",
      "ALL: 0.09365940693409676\n"
     ]
    }
   ],
   "source": [
    "prep_params = {\n",
    "    'encoding__columns':['intersection_id'],\n",
    "    'feature_select__k':  'all'\n",
    "}\n",
    "\n",
    "feature_process = [\n",
    "    ('weather', WeatherFeatures(weather)),\n",
    "    ('last2hour', LastTwoHour()),\n",
    "]\n",
    "\n",
    "estimators = [\n",
    "    ('transformed_time', TimeProcessor('time_start')),\n",
    "    ('encoding',MultiColumnLabelEncoder(columns=['intersection_id'])),\n",
    "    ('drop', DropProcessor(['time_start', 'time_end'])),\n",
    "    ('save_table', Saver('../Before.pickle')),\n",
    "    ('combined_features', FeatureUnion(feature_process)),\n",
    "    ('feature_select', feature_selector),\n",
    "]\n",
    "\n",
    "preprocess = Pipeline(estimators)\n",
    "preprocess.set_params(**prep_params)\n",
    "\n",
    "t = (train_avg_travel_time.time_start < '2016-10-8') & (train_avg_travel_time.time_start > '2016-9-30')\n",
    "t = t & (train_avg_volume.time_start < '2016-9-1')\n",
    "#trafic_train = pd.read_csv('../trafic_train.csv')\n",
    "tt = train_avg_travel_time.time_start.apply(lambda x: (x.hour < 10) & (x.hour >= 8))\n",
    "t = (~t) & tt\n",
    "t2 = train_avg_travel_time[t]\n",
    "train_x=t2.drop(['avg_travel_time'], axis=1)\n",
    "train_y=t2.avg_travel_time\n",
    "\n",
    "train_x.index = range(len(train_x))\n",
    "train_y.index = range(len(train_y))\n",
    "train_x=preprocess.fit_transform(train_x, train_y)\n",
    "group=train_x[:,4]\n",
    "\n",
    "clf = param_search.fit(train_x, train_y, groups=group)\n",
    "param_search.cv_results_\n",
    "param_search.best_params_\n",
    "\n",
    "param_search.best_estimator_.verbose=0\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "i = 0\n",
    "clf2 = param_search.best_estimator_\n",
    "print(param_search.best_score_)\n",
    "print(param_search.best_params_)\n",
    "\n",
    "for train, test in gkf.split(train_x, train_y, groups=group):\n",
    "    clf2.fit(train_x[train], train_y[train])\n",
    "    print('* {}: train:{}, test:{}'.format(i,\n",
    "        mean_absolute_percentage_error(train_y[train],  clf2.predict(train_x[train])),\n",
    "        mean_absolute_percentage_error(train_y[test],  clf2.predict(train_x[test]))))\n",
    "    i+=1\n",
    "    \n",
    "clf2.fit(train_x, train_y)\n",
    "print('ALL:', mean_absolute_percentage_error(train_y,  clf2.predict(train_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.externals import joblib\\nfrom sklearn.pipeline import make_pipeline\\npipe = Pipeline([\\n    ('preprocess', preprocess),\\n    ('best_estimator', param_search.best_estimator_)\\n])\\njoblib.dump(pipe, 'model.pkl')\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.externals import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('best_estimator', param_search.best_estimator_)\n",
    "])\n",
    "joblib.dump(pipe, 'model.pkl')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../submission_sample_travelTime.csv').drop('avg_travel_time', axis = 1)\n",
    "test_x = pd.read_csv('../submission_sample_travelTime.csv').drop('avg_travel_time', axis = 1)\n",
    "test_x['time_start'], test_x['time_end'] = split_time_window(test_x.time_window)\n",
    "test_x = test_x.drop(['time_window'], axis=1)\n",
    "\n",
    "test_x = preprocess.transform(test_x)\n",
    "\n",
    "clf = param_search.best_estimator_.fit(train_x, train_y)\n",
    "submission['avg_travel_time'] =  clf.predict(test_x)\n",
    "from datetime import date\n",
    "submission.to_csv('time{}.{}.{}.csv'.format(\n",
    "    str(now.date()),\n",
    "    str(now.hour),\n",
    "    str(now.minute)\n",
    "), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0: train:0.1330235916580782, test:0.4074928715153546\n",
      "* 1: train:0.12624506285864784, test:0.2536316787832385\n",
      "* 2: train:0.1301320127167199, test:0.1997518119381972\n",
      "* 3: train:0.11482277394445752, test:0.5584647104069047\n"
     ]
    }
   ],
   "source": [
    "feature_process = [\n",
    "    ('weather', WeatherFeatures(weather)),\n",
    "    ('last2hour', LastTwoHour()),\n",
    "]\n",
    "combined_features = FeatureUnion(feature_process)\n",
    "\n",
    "estimators = [\n",
    "    ('transformed_time', TimeProcessor('time_start')),\n",
    "    #('encoding',MultiColumnLabelEncoder(columns=['intersection_id'])),\n",
    "    ('drop', DropProcessor(['time_start', 'time_end'])),\n",
    "    ('save_table', Saver('../VolumeBefore.pickle')),\n",
    "    ('combined_features', combined_features),\n",
    "    #('feature_select', feature_selector),\n",
    "]\n",
    "\n",
    "preprocess = Pipeline(estimators)\n",
    "\n",
    "t = (train_avg_volume.time_start < '2016-10-8') & (train_avg_volume.time_start > '2016-10-1')\n",
    "t = t & (train_avg_volume.time_start < '2016-9-1')\n",
    "tt = train_avg_volume.time_start.apply(lambda x: (x.hour < 10) & (x.hour >= 8))\n",
    "t = (~t) & tt\n",
    "t = train_avg_volume[t]\n",
    "train_x = t.drop(['volume'], axis=1)\n",
    "train_y = t.volume\n",
    "\n",
    "train_x.index = range(len(train_x))\n",
    "train_y.index = range(len(train_y))\n",
    "\n",
    "train_x = preprocess.transform(train_x)\n",
    "\n",
    "group=train_x[:,4]\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "i = 0\n",
    "clf = param_search.best_estimator_\n",
    "\n",
    "for train, test in gkf.split(train_x, train_y, groups=group):\n",
    "    clf.fit(train_x[train], train_y[train])\n",
    "    print('* {}: train:{}, test:{}'.format(i,\n",
    "        mean_absolute_percentage_error(train_y[train],  clf.predict(train_x[train])),\n",
    "        mean_absolute_percentage_error(train_y[test],  clf.predict(train_x[test]))))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12711060216930561\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('../submission_sample_volume.csv').drop('volume', axis = 1)\n",
    "test_x = pd.read_csv('../submission_sample_volume.csv').drop('volume', axis = 1)\n",
    "test_x['time_start'], test_x['time_end'] = split_time_window(test_x.time_window)\n",
    "test_x = test_x.drop(['time_window'], axis=1)\n",
    "\n",
    "test_x = preprocess.transform(test_x)\n",
    "\n",
    "clf = param_search.best_estimator_.fit(train_x, train_y)\n",
    "print(mean_absolute_percentage_error(train_y,  clf.predict(train_x)))\n",
    "submission['volume'] =  clf.predict(test_x)\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "submission.to_csv('volume{}.{}.{}.csv'.format(\n",
    "    str(now.date()),\n",
    "    str(now.hour),\n",
    "    str(now.minute)\n",
    "), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
