{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辅助函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Tools import *\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "mape = make_scorer(mean_absolute_percentage_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    'trajectories': pd.read_csv('../trajectories(table 5)_training.csv'),\n",
    "    'volume': pd.read_csv('../volume(table 6)_training.csv'),\n",
    "    'avg_travel_time': pd.read_csv('../training_20min_avg_travel_time.csv'),\n",
    "    'avg_volume': pd.read_csv('../training_20min_avg_volume.csv'),\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    'trajectories': pd.read_csv('../trajectories(table 5)_training.csv'),\n",
    "    'volume': pd.read_csv('../volume(table 6)_training.csv'),\n",
    "    'avg_travel_time': pd.read_csv('../test1_20min_avg_travel_time.csv'),\n",
    "    'avg_volume': pd.read_csv('../test1_20min_avg_volume.csv'),\n",
    "}\n",
    "\n",
    "links = pd.read_csv('../links (table 3).csv')\n",
    "routes = pd.read_csv('../routes (table 4).csv')\n",
    "weather = pd.concat([\n",
    "    pd.read_csv('../weather (table 7)_training_update.csv'),\n",
    "    pd.read_csv('../weather (table 7)_test1.csv')])\n",
    "\n",
    "train_path = pd.read_csv('../train_avg_travel_time_4h&path.csv').drop(\n",
    "    ['Unnamed: 0', 'time_window_start', 'time_start_of_day'], axis=1)\n",
    "\n",
    "test_path = pd.read_csv('../test_avg_travel_time_4h&path.csv').drop(\n",
    "    ['Unnamed: 0', 'time_window_start', 'time_start_of_day'], axis=1)\n",
    "\n",
    "train_trajectories = train_data['trajectories']\n",
    "train_volume = train_data['volume']\n",
    "\n",
    "train_avg_travel_time = train_data['avg_travel_time']\n",
    "train_avg_travel_time = train_avg_travel_time.merge(train_path, how='left')\n",
    "\n",
    "train_avg_volume = train_data['avg_volume']\n",
    "\n",
    "test_avg_travel_time = test_data['avg_travel_time']\n",
    "test_avg_travel_time = test_avg_travel_time.merge(test_path, how='left')\n",
    "\n",
    "test_avg_volume = test_data['avg_volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  整理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 处理天气数据 插值填充每小时数据\n",
    "\n",
    "weather.date = pd.to_datetime(weather.date)\n",
    "weather['time'] = weather.date + pd.to_timedelta(weather.hour, unit='h')\n",
    "\n",
    "weather = weather.set_index(['time'])\n",
    "weather = weather.reindex(pd.date_range(start= weather.date.min(), end=weather.date.max(), freq='1H'), fill_value='NaN')\n",
    "\n",
    "weather['date'] = pd.to_datetime([t.date() for t in weather.index])\n",
    "weather['year'] = [t.year for t in weather.index]\n",
    "weather['day_of_year'] = [t.dayofyear for t in weather.index]\n",
    "weather['hour'] = [t.hour for t in weather.index]\n",
    "for col in ['pressure', 'sea_pressure', 'wind_direction', 'wind_speed', 'temperature', 'rel_humidity', 'precipitation']:\n",
    "    weather[col] = weather[col].astype(float).interpolate()\n",
    "    \n",
    "weather = weather.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(weather, 'weather.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 拆分时间窗\n",
    "\n",
    "def split_time_window(time_window):\n",
    "    time_start = [time[1:-1].split(',')[0] for time in time_window]\n",
    "    time_end = [time[1:-1].split(',')[1] for time in time_window]\n",
    "\n",
    "    return pd.to_datetime(pd.Series(time_start)), pd.to_datetime(pd.Series(time_end))\n",
    "\n",
    "train_avg_volume['time_start'], train_avg_volume['time_end'] = split_time_window(train_avg_volume.time_window)\n",
    "train_avg_volume = train_avg_volume.drop(['time_window'], axis=1)\n",
    "\n",
    "train_avg_travel_time['time_start'], train_avg_travel_time['time_end'] = split_time_window(train_avg_travel_time.time_window)\n",
    "train_avg_travel_time = train_avg_travel_time.drop(['time_window'], axis=1)\n",
    "\n",
    "test_avg_volume['time_start'], test_avg_volume['time_end'] = split_time_window(test_avg_volume.time_window)\n",
    "test_avg_volume = test_avg_volume.drop(['time_window'], axis=1)\n",
    "\n",
    "test_avg_travel_time['time_start'], test_avg_travel_time['time_end'] = split_time_window(test_avg_travel_time.time_window)\n",
    "test_avg_travel_time = test_avg_travel_time.drop(['time_window'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Preprocess.TimeProcessor import *\n",
    "from Preprocess.Utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 天气特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WeatherFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, weather):\n",
    "        self.weather = weather\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        table = posts.merge(self.weather,  how='left' ,on=['year','day_of_year','hour'])\n",
    "        return table.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 前两小时特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LastTwoHour(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        #self.traffic = pd.read_csv('../trafic_train.csv')\n",
    "    \n",
    "    def fit(self,x,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, posts):\n",
    "        return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_process = [\n",
    "    ('weather', WeatherFeatures(weather)),\n",
    "    #('last2hour', LastTwoHour()),\n",
    "]\n",
    "combined_features = FeatureUnion(feature_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "feature_selector = SelectKBest(k=all)\n",
    "\n",
    "from sklearn.feature_selection import GenericUnivariateSelect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('transformed_time', TimeProcessor('time_start')),\n",
    "    ('encoding',MultiColumnLabelEncoder(columns=['intersection_id'])),\n",
    "    ('drop', DropProcessor(['time_start', 'time_end'])),\n",
    "    ('save_table', Saver('../Before.pickle')),\n",
    "    ('combined_features', combined_features),\n",
    "    ('feature_select', feature_selector),\n",
    "]\n",
    "\n",
    "preprocess = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yecheng/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "def log(x):\n",
    "    return np.log(x)\n",
    "\n",
    "#TODO: 0.65*abs(x) * log(abs(x) + 1)\n",
    "def obj1(y_true, y_pred):\n",
    "    x = y_true - y_pred\n",
    "    absx = np.abs(x)\n",
    "    \n",
    "    grad =((x*abs(x)+x)*log(abs(x)+1)+x*abs(x))/(abs(x)+x**2)\n",
    "    hess =(2*abs(x)+x**2)/(x**2*abs(x)+abs(x)+2*x**2)\n",
    "    return grad, hess\n",
    "\n",
    "def obj2(y_true, y_pred):\n",
    "    tmp = y_true - y_pred\n",
    "    hess = 2 / y_true    \n",
    "    grad = - hess *  tmp\n",
    "       \n",
    "    return grad, hess\n",
    "\n",
    "'''\n",
    "    sig = np.sign(y_true - y_pred)\n",
    "    grad = sig#(sig *  (-1 / y_true)) * 10\n",
    "    hess = np.zeros(len(y_true))\n",
    "    return grad, hess\n",
    "'''\n",
    "xgb = XGBRegressor(objective=obj2)\n",
    "\n",
    "regressors = [\n",
    "    #LinearRegression(),\n",
    "    #RandomForestRegressor(),\n",
    "    #ExtraTreesRegressor(),\n",
    "    #LGBMRegressor(objective=obj2),\n",
    "    LGBMRegressor(boosting_type='dart', objective= obj2),\n",
    "    XGBRegressor(objective=obj2),\n",
    "    #SVR()\n",
    "]\n",
    "\n",
    "stack = StackingRegressor(regressors=regressors,meta_regressor=xgb,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>预处理参数</h1>\n",
       "<h2>transformed_time</h2>\n",
       "<ul>\n",
       "<li>transformed_time__column</li>\n",
       "<li>transformed_time__title</li>\n",
       "</ul>\n",
       "<h2>encoding</h2>\n",
       "<ul>\n",
       "<li>encoding__columns</li>\n",
       "</ul>\n",
       "<h2>drop</h2>\n",
       "<ul>\n",
       "<li>drop__columns</li>\n",
       "</ul>\n",
       "<h2>save_table</h2>\n",
       "<ul>\n",
       "<li>save_table__path</li>\n",
       "</ul>\n",
       "<h2>combined_features</h2>\n",
       "<ul>\n",
       "<li>combined_features__n_jobs</li>\n",
       "<li>combined_features__transformer_list</li>\n",
       "<li>combined_features__transformer_weights</li>\n",
       "<li>combined_features__weather</li>\n",
       "<li>combined_features__weather__weather</li>\n",
       "</ul>\n",
       "<h2>feature_select</h2>\n",
       "<ul>\n",
       "<li>feature_select__k</li>\n",
       "<li>feature_select__score_func</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayParam(preprocess, ['<h1>预处理参数</h1>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>训练参数</h1>\n",
       "<h2>lgbmregressor</h2>\n",
       "<ul>\n",
       "<li>lgbmregressor__boosting_type</li>\n",
       "<li>lgbmregressor__colsample_bytree</li>\n",
       "<li>lgbmregressor__drop_rate</li>\n",
       "<li>lgbmregressor__fair_c</li>\n",
       "<li>lgbmregressor__gaussian_eta</li>\n",
       "<li>lgbmregressor__huber_delta</li>\n",
       "<li>lgbmregressor__learning_rate</li>\n",
       "<li>lgbmregressor__max_bin</li>\n",
       "<li>lgbmregressor__max_depth</li>\n",
       "<li>lgbmregressor__max_drop</li>\n",
       "<li>lgbmregressor__min_child_samples</li>\n",
       "<li>lgbmregressor__min_child_weight</li>\n",
       "<li>lgbmregressor__min_split_gain</li>\n",
       "<li>lgbmregressor__n_estimators</li>\n",
       "<li>lgbmregressor__nthread</li>\n",
       "<li>lgbmregressor__num_leaves</li>\n",
       "<li>lgbmregressor__objective</li>\n",
       "<li>lgbmregressor__poisson_max_delta_step</li>\n",
       "<li>lgbmregressor__reg_alpha</li>\n",
       "<li>lgbmregressor__reg_lambda</li>\n",
       "<li>lgbmregressor__seed</li>\n",
       "<li>lgbmregressor__silent</li>\n",
       "<li>lgbmregressor__skip_drop</li>\n",
       "<li>lgbmregressor__subsample</li>\n",
       "<li>lgbmregressor__subsample_for_bin</li>\n",
       "<li>lgbmregressor__subsample_freq</li>\n",
       "<li>lgbmregressor__uniform_drop</li>\n",
       "<li>lgbmregressor__xgboost_dart_mode</li>\n",
       "</ul>\n",
       "<h2>xgbregressor</h2>\n",
       "<ul>\n",
       "<li>xgbregressor__base_score</li>\n",
       "<li>xgbregressor__colsample_bylevel</li>\n",
       "<li>xgbregressor__colsample_bytree</li>\n",
       "<li>xgbregressor__gamma</li>\n",
       "<li>xgbregressor__learning_rate</li>\n",
       "<li>xgbregressor__max_delta_step</li>\n",
       "<li>xgbregressor__max_depth</li>\n",
       "<li>xgbregressor__min_child_weight</li>\n",
       "<li>xgbregressor__missing</li>\n",
       "<li>xgbregressor__n_estimators</li>\n",
       "<li>xgbregressor__nthread</li>\n",
       "<li>xgbregressor__objective</li>\n",
       "<li>xgbregressor__reg_alpha</li>\n",
       "<li>xgbregressor__reg_lambda</li>\n",
       "<li>xgbregressor__scale_pos_weight</li>\n",
       "<li>xgbregressor__seed</li>\n",
       "<li>xgbregressor__silent</li>\n",
       "<li>xgbregressor__subsample</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayParam(stack, ['<h1>训练参数</h1>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "prep_params = {\n",
    "    'encoding__columns':['intersection_id'],\n",
    "    'feature_select__k':  'all'\n",
    "}\n",
    "\n",
    "stack_params = {\n",
    "    #model\n",
    "    'lgbmregressor__n_estimators': [100,300,500],\n",
    "    'xgbregressor__n_estimators': [100,300,500,700],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess.set_params(**prep_params)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_search = RandomizedSearchCV(\n",
    "    estimator=stack,\n",
    "    param_distributions=stack_params, \n",
    "    scoring=mape, \n",
    "    n_iter=6,\n",
    "    cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yecheng/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/home/yecheng/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "t = (train_avg_travel_time.time_start < '2016-10-8') & (train_avg_travel_time.time_start > '2016-10-1')\n",
    "#trafic_train = pd.read_csv('../trafic_train.csv')\n",
    "\n",
    "t2 = train_avg_travel_time.drop(t)\n",
    "train_x=t2.drop(['avg_travel_time'], axis=1)\n",
    "train_y=t2.avg_travel_time\n",
    "\n",
    "train_x.index = range(len(train_x))\n",
    "train_y.index = range(len(train_y))\n",
    "train_x=preprocess.fit_transform(train_x, train_y)\n",
    "group=train_x[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: lgbmregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n"
     ]
    }
   ],
   "source": [
    "clf = param_search.fit(train_x, train_y, groups=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_search.best_estimator_.verbose=0\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "i = 0\n",
    "clf2 = param_search.best_estimator_\n",
    "#clf2 = LinearRegression()\n",
    "\n",
    "for train, test in gkf.split(train_x, train_y, groups=group):\n",
    "    clf2.fit(train_x[train], train_y[train])\n",
    "    print('* {}: train:{}, test:{}'.format(i,\n",
    "        mean_absolute_percentage_error(train_y[train],  clf2.predict(train_x[train])),\n",
    "        mean_absolute_percentage_error(train_y[test],  clf2.predict(train_x[test]))))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''from sklearn.externals import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('best_estimator', param_search.best_estimator_)\n",
    "])\n",
    "joblib.dump(pipe, 'model.pkl')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../submission_sample_travelTime.csv').drop('avg_travel_time', axis = 1)\n",
    "test_x = pd.read_csv('../submission_sample_travelTime.csv').drop('avg_travel_time', axis = 1)\n",
    "test_x['time_start'], test_x['time_end'] = split_time_window(test_x.time_window)\n",
    "test_x = test_x.drop(['time_window'], axis=1)\n",
    "\n",
    "test_x = preprocess.transform(test_x)\n",
    "\n",
    "clf = param_search.best_estimator_.fit(train_x, train_y)\n",
    "submission['avg_travel_time'] =  clf.predict(test_x)\n",
    "submission.to_csv('avg_travel_time.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_avg_travel_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
