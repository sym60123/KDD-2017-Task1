{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'links (table 3).csv',\n",
       " 'routes (table 4).csv',\n",
       " 'trajectories(table 5)_training.csv',\n",
       " 'volume(table 6)_training.csv',\n",
       " 'weather (table 7)_training.csv',\n",
       " 'scripts',\n",
       " '__MACOSX',\n",
       " 'training_20min_avg_travel_time.csv',\n",
       " 'training_20min_avg_volume.csv',\n",
       " 'A2.csv',\n",
       " 'A3.csv',\n",
       " 'B1.csv',\n",
       " 'B3.csv',\n",
       " 'C1.csv',\n",
       " 'C3.csv',\n",
       " 'test1_20min_avg_volume.csv',\n",
       " 'test1_20min_avg_travel_time.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'links': pd.read_csv('../links (table 3).csv'),\n",
    "    'routes': pd.read_csv('../routes (table 4).csv'),\n",
    "    'trajectories': pd.read_csv('../trajectories(table 5)_training.csv'),\n",
    "    'volume': pd.read_csv('../volume(table 6)_training.csv'),\n",
    "    'weather': pd.read_csv('../weather (table 7)_training.csv'),\n",
    "    'avg_travel_time': pd.read_csv('../training_20min_avg_travel_time.csv'),\n",
    "    'avg_volume': pd.read_csv('../training_20min_avg_volume.csv')\n",
    "}\n",
    "\n",
    "links = data['links']\n",
    "routes = data['routes']\n",
    "trajectories = data['trajectories']\n",
    "volume = data['volume']\n",
    "weather = data['weather']\n",
    "avg_travel_time = data['avg_travel_time']\n",
    "avg_volume = data['avg_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.4</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>26.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.5</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>6</td>\n",
       "      <td>998.9</td>\n",
       "      <td>1003.7</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>31.7</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>9</td>\n",
       "      <td>998.7</td>\n",
       "      <td>1003.5</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>12</td>\n",
       "      <td>999.7</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour  pressure  sea_pressure  wind_direction  wind_speed  \\\n",
       "0  2016-07-01     0    1000.4        1005.3           225.0         2.1   \n",
       "1  2016-07-01     3    1000.5        1005.3           187.0         2.7   \n",
       "2  2016-07-01     6     998.9        1003.7           212.0         2.9   \n",
       "3  2016-07-01     9     998.7        1003.5           244.0         2.7   \n",
       "4  2016-07-01    12     999.7        1004.5           222.0         1.3   \n",
       "\n",
       "   temperature  rel_humidity  precipitation  \n",
       "0         26.4          94.0            0.0  \n",
       "1         29.0          76.0            0.0  \n",
       "2         31.7          67.0            0.0  \n",
       "3         31.6          59.0            0.0  \n",
       "4         29.9          68.0            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>lanes</th>\n",
       "      <th>in_top</th>\n",
       "      <th>out_top</th>\n",
       "      <th>lane_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>131</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>122,116</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   link_id  length  width  lanes in_top  out_top  lane_width\n",
       "0      100      58      3      1    105      111           3\n",
       "1      101      84      3      1    116      121           3\n",
       "2      102     131      9      3    115      109           3\n",
       "3      103      23     12      4    111  122,116           3\n",
       "4      104     293      9      3    109      112           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_travel_time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_window</th>\n",
       "      <th>avg_travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>[2016-07-19 00:00:00,2016-07-19 00:20:00)</td>\n",
       "      <td>70.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>[2016-07-19 00:20:00,2016-07-19 00:40:00)</td>\n",
       "      <td>148.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>[2016-07-19 01:40:00,2016-07-19 02:00:00)</td>\n",
       "      <td>93.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>[2016-07-19 02:00:00,2016-07-19 02:20:00)</td>\n",
       "      <td>67.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>[2016-07-19 02:40:00,2016-07-19 03:00:00)</td>\n",
       "      <td>167.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intersection_id  tollgate_id                                time_window  \\\n",
       "0               B            3  [2016-07-19 00:00:00,2016-07-19 00:20:00)   \n",
       "1               B            3  [2016-07-19 00:20:00,2016-07-19 00:40:00)   \n",
       "2               B            3  [2016-07-19 01:40:00,2016-07-19 02:00:00)   \n",
       "3               B            3  [2016-07-19 02:00:00,2016-07-19 02:20:00)   \n",
       "4               B            3  [2016-07-19 02:40:00,2016-07-19 03:00:00)   \n",
       "\n",
       "   avg_travel_time  \n",
       "0            70.85  \n",
       "1           148.79  \n",
       "2            93.72  \n",
       "3            67.81  \n",
       "4           167.55  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_volume\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_window</th>\n",
       "      <th>direction</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[2016-09-19 00:00:00,2016-09-19 00:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-09-19 00:00:00,2016-09-19 00:20:00)</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2016-09-19 00:00:00,2016-09-19 00:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2016-09-19 00:00:00,2016-09-19 00:20:00)</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[2016-09-19 00:00:00,2016-09-19 00:20:00)</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tollgate_id                                time_window  direction  volume\n",
       "0            2  [2016-09-19 00:00:00,2016-09-19 00:20:00)          0       2\n",
       "1            1  [2016-09-19 00:00:00,2016-09-19 00:20:00)          1     140\n",
       "2            1  [2016-09-19 00:00:00,2016-09-19 00:20:00)          0      13\n",
       "3            3  [2016-09-19 00:00:00,2016-09-19 00:20:00)          1     181\n",
       "4            3  [2016-09-19 00:00:00,2016-09-19 00:20:00)          0      17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>direction</th>\n",
       "      <th>vehicle_model</th>\n",
       "      <th>has_etc</th>\n",
       "      <th>vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-19 23:09:25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-19 23:11:53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-19 23:13:54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-19 23:17:48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-19 23:16:07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  tollgate_id  direction  vehicle_model  has_etc  \\\n",
       "0  2016-09-19 23:09:25            2          0              1        0   \n",
       "1  2016-09-19 23:11:53            2          0              1        0   \n",
       "2  2016-09-19 23:13:54            2          0              1        0   \n",
       "3  2016-09-19 23:17:48            1          0              1        1   \n",
       "4  2016-09-19 23:16:07            2          0              1        0   \n",
       "\n",
       "   vehicle_type  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>link_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>110,123,107,108,120,117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>110,123,107,108,119,114,118,122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>105,100,111,103,116,101,121,106,113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>105,100,111,103,122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>115,102,109,104,112,111,103,116,101,121,106,113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intersection_id  tollgate_id  \\\n",
       "0               A            2   \n",
       "1               A            3   \n",
       "2               B            1   \n",
       "3               B            3   \n",
       "4               C            1   \n",
       "\n",
       "                                          link_seq  \n",
       "0                          110,123,107,108,120,117  \n",
       "1                  110,123,107,108,119,114,118,122  \n",
       "2              105,100,111,103,116,101,121,106,113  \n",
       "3                              105,100,111,103,122  \n",
       "4  115,102,109,104,112,111,103,116,101,121,106,113  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectories\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>starting_time</th>\n",
       "      <th>travel_seq</th>\n",
       "      <th>travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>1065642</td>\n",
       "      <td>2016-07-19 00:14:24</td>\n",
       "      <td>105#2016-07-19 00:14:24#9.56;100#2016-07-19 00...</td>\n",
       "      <td>70.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>1047198</td>\n",
       "      <td>2016-07-19 00:35:56</td>\n",
       "      <td>105#2016-07-19 00:35:56#11.58;100#2016-07-19 0...</td>\n",
       "      <td>148.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1086390</td>\n",
       "      <td>2016-07-19 00:37:15</td>\n",
       "      <td>105#2016-07-19 00:37:15#5.26;100#2016-07-19 00...</td>\n",
       "      <td>79.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1071181</td>\n",
       "      <td>2016-07-19 00:37:59</td>\n",
       "      <td>110#2016-07-19 00:37:59#13.74;123#2016-07-19 0...</td>\n",
       "      <td>58.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1065807</td>\n",
       "      <td>2016-07-19 00:56:21</td>\n",
       "      <td>105#2016-07-19 00:56:21#16.08;100#2016-07-19 0...</td>\n",
       "      <td>137.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intersection_id  tollgate_id  vehicle_id        starting_time  \\\n",
       "0               B            3     1065642  2016-07-19 00:14:24   \n",
       "1               B            3     1047198  2016-07-19 00:35:56   \n",
       "2               B            1     1086390  2016-07-19 00:37:15   \n",
       "3               A            2     1071181  2016-07-19 00:37:59   \n",
       "4               B            1     1065807  2016-07-19 00:56:21   \n",
       "\n",
       "                                          travel_seq  travel_time  \n",
       "0  105#2016-07-19 00:14:24#9.56;100#2016-07-19 00...        70.85  \n",
       "1  105#2016-07-19 00:35:56#11.58;100#2016-07-19 0...       148.79  \n",
       "2  105#2016-07-19 00:37:15#5.26;100#2016-07-19 00...        79.76  \n",
       "3  110#2016-07-19 00:37:59#13.74;123#2016-07-19 0...        58.05  \n",
       "4  105#2016-07-19 00:56:21#16.08;100#2016-07-19 0...       137.98  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "for table_name in data:\n",
    "    table = data[table_name]\n",
    "    print(table_name)\n",
    "    display(table.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_time_window(time_window):\n",
    "    time_start = [time[1:-1].split(',')[0] for time in time_window]\n",
    "    time_end = [time[1:-1].split(',')[1] for time in time_window]\n",
    "\n",
    "    return pd.to_datetime(pd.Series(time_start)), pd.to_datetime(pd.Series(time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_travel_time['time_start'], avg_travel_time['time_end'] = split_time_window(avg_travel_time.time_window)\n",
    "avg_travel_time = avg_travel_time.drop(['time_window'], axis=1)\n",
    "\n",
    "avg_volume['time_start'], avg_volume['time_end'] = split_time_window(avg_volume.time_window)\n",
    "avg_volume = avg_volume.drop(['time_window'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>avg_travel_time</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>70.85</td>\n",
       "      <td>2016-07-19 00:00:00</td>\n",
       "      <td>2016-07-19 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>148.79</td>\n",
       "      <td>2016-07-19 00:20:00</td>\n",
       "      <td>2016-07-19 00:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>93.72</td>\n",
       "      <td>2016-07-19 01:40:00</td>\n",
       "      <td>2016-07-19 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>67.81</td>\n",
       "      <td>2016-07-19 02:00:00</td>\n",
       "      <td>2016-07-19 02:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>167.55</td>\n",
       "      <td>2016-07-19 02:40:00</td>\n",
       "      <td>2016-07-19 03:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intersection_id  tollgate_id  avg_travel_time          time_start  \\\n",
       "0               B            3            70.85 2016-07-19 00:00:00   \n",
       "1               B            3           148.79 2016-07-19 00:20:00   \n",
       "2               B            3            93.72 2016-07-19 01:40:00   \n",
       "3               B            3            67.81 2016-07-19 02:00:00   \n",
       "4               B            3           167.55 2016-07-19 02:40:00   \n",
       "\n",
       "             time_end  \n",
       "0 2016-07-19 00:20:00  \n",
       "1 2016-07-19 00:40:00  \n",
       "2 2016-07-19 02:00:00  \n",
       "3 2016-07-19 02:20:00  \n",
       "4 2016-07-19 03:00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_travel_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection_id</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>avg_travel_time</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>94.57</td>\n",
       "      <td>2016-07-19 01:20:00</td>\n",
       "      <td>2016-07-19 01:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>77.61</td>\n",
       "      <td>2016-07-19 02:20:00</td>\n",
       "      <td>2016-07-19 02:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>93.09</td>\n",
       "      <td>2016-07-19 03:00:00</td>\n",
       "      <td>2016-07-19 03:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>91.61</td>\n",
       "      <td>2016-07-19 04:40:00</td>\n",
       "      <td>2016-07-19 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>168.36</td>\n",
       "      <td>2016-07-19 05:20:00</td>\n",
       "      <td>2016-07-19 05:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     intersection_id  tollgate_id  avg_travel_time          time_start  \\\n",
       "4803               A            3            94.57 2016-07-19 01:20:00   \n",
       "4804               A            3            77.61 2016-07-19 02:20:00   \n",
       "4805               A            3            93.09 2016-07-19 03:00:00   \n",
       "4806               A            3            91.61 2016-07-19 04:40:00   \n",
       "4807               A            3           168.36 2016-07-19 05:20:00   \n",
       "\n",
       "                time_end  \n",
       "4803 2016-07-19 01:40:00  \n",
       "4804 2016-07-19 02:40:00  \n",
       "4805 2016-07-19 03:20:00  \n",
       "4806 2016-07-19 05:00:00  \n",
       "4807 2016-07-19 05:40:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_travel_time[avg_travel_time.intersection_id == 'A'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Time Seq\n",
    "def get_avg_time(intersection_id, tollgate_id):\n",
    "    intersection = avg_travel_time[avg_travel_time.intersection_id == intersection_id]\n",
    "    table = intersection[intersection.tollgate_id == tollgate_id]\n",
    "    if len(table) == 0:\n",
    "        return None\n",
    "    return table[['time_start','avg_travel_time']].set_index('time_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = ['A', 'B', 'C']\n",
    "tollgates = [1, 2, 3]\n",
    "\n",
    "for name in names:\n",
    "    for tollgate in tollgates:\n",
    "        seq = get_avg_time(name, tollgate)\n",
    "        \n",
    "        if seq is not None:\n",
    "            seq.to_csv('../{}{}.csv'.format(name, tollgate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def handleTime(time):\n",
    "    return pd.DataFrame({\n",
    "        \"date\": pd.Series([t.date() for t in time]),\n",
    "        \"day_in_month\": pd.Series([t.daysinmonth for t in time]), \n",
    "        \"day_of_year\": pd.Series([t.dayofyear for t in time]),\n",
    "        \"day_of_week\": pd.Series([t.dayofweek for t in time]),\n",
    "        \"hour\": pd.Series([t.hour for t in time]),\n",
    "        \"month\": pd.Series([t.month for t in time]),\n",
    "        \"minute\": pd.Series([t.minute for t in time]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_avg_volume = pd.read_csv('../test1_20min_avg_travel_time.csv')\n",
    "\n",
    "test_avg_volume['time_start'], test_avg_volume['time_end'] = split_time_window(test_avg_volume.time_window)\n",
    "test_avg_volume = test_avg_volume.drop(['time_window'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理Avg Travel Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def avg_travel_time_preprocess(avg_travel_time, weather):\n",
    "    table = avg_travel_time.join(handleTime(avg_travel_time.time_start))\n",
    "    '''\n",
    "    weather.date = pd.to_datetime(weather.date)\n",
    "    weather.date = [t.date() for t in weather.date]\n",
    "\n",
    "    table.merge(weather, on=['date','hour'])\n",
    "    '''\n",
    "    enconder = LabelEncoder()\n",
    "    \n",
    "    table.intersection_id = enconder.fit_transform(y=table.intersection_id)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = avg_travel_time_preprocess(avg_travel_time, weather)\n",
    "test_table = avg_travel_time_preprocess(test_avg_volume, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "loss = make_scorer(mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.feature_selection import SelectFromModel\\nselector = SelectFromModel(model)\\nselector.fit(X=train_x, y=train_y)\\ntrain_x = selector.fit_transform(X=train_x, y=train_y)\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = (table['time_start'] > '2015-7-1') & (table['time_start'] < '2017-8-1')\n",
    "train_x = table[ind]\n",
    "train_x = train_x.drop(['avg_travel_time', 'time_start', 'time_end', 'date'], axis=1)\n",
    "train_y = avg_travel_time.avg_travel_time[ind]\n",
    "\n",
    "'''\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "selector = SelectFromModel(model)\n",
    "selector.fit(X=train_x, y=train_y)\n",
    "train_x = selector.fit_transform(X=train_x, y=train_y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f3ee3b2fae0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/yechen.../python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f3ee3b2fae0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/yechen.../python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    648 \n    649         If a global instance already exists, this reinitializes and starts it\n    650         \"\"\"\n    651         app = cls.instance(**kwargs)\n    652         app.initialize(argv)\n--> 653         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    654 \n    655 #-----------------------------------------------------------------------------\n    656 # utility functions, for convenience\n    657 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-04-04T16:28:49.376575', 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'session': '81B9D28FBEA24355AFCFC9A0F904F383', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'81B9D28FBEA24355AFCFC9A0F904F383']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-04-04T16:28:49.376575', 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'session': '81B9D28FBEA24355AFCFC9A0F904F383', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'81B9D28FBEA24355AFCFC9A0F904F383'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-04-04T16:28:49.376575', 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'session': '81B9D28FBEA24355AFCFC9A0F904F383', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-117-0c68ea15d7d3>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f3e7bf0dcf8, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3ea5712390, file \"<ipython-input-117-0c68ea15d7d3>\", line 33>\n        result = <ExecutionResult object at 7f3e7bf0dcf8, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3ea5712390, file \"<ipython-input-117-0c68ea15d7d3>\", line 33>, result=<ExecutionResult object at 7f3e7bf0dcf8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3ea5712390, file \"<ipython-input-117-0c68ea15d7d3>\", line 33>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HTML': <class 'IPython.core.display.HTML'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport sklearn as sk', 'import os\\nfrom matplotlib import pyplot as plt\\nimport seaborn as sbn', \"get_ipython().magic('matplotlib inline')\\nplt.style.use('seaborn-paper')\", \"os.listdir('..')\", \"data = {\\n    'links': pd.read_csv('../links (tab...avg_travel_time']\\navg_volume = data['avg_volume']\", 'from IPython.display import display, HTML\\n\\nfor t...\\n    print(table_name)\\n    display(table.head(5))', 'def split_time_window(time_window):\\n    time_sta...time_start)), pd.to_datetime(pd.Series(time_end))', \"avg_travel_time['time_start'], avg_travel_time['...volume = avg_volume.drop(['time_window'], axis=1)\", 'avg_travel_time.head()', \"avg_travel_time[avg_travel_time.intersection_id == 'A'].head()\", \"# Time Seq\\ndef get_avg_time(intersection_id, tol...tart','avg_travel_time']].set_index('time_start')\", \"names = ['A', 'B', 'C']\\ntollgates = [1, 2, 3]\\n\\nf... seq.to_csv('../{}{}.csv'.format(name, tollgate))\", 'def handleTime(time):\\n    return pd.DataFrame({\\n...ute\": pd.Series([t.minute for t in time]),\\n    })', \"test_avg_volume = pd.read_csv('../test1_20min_av...e = test_avg_volume.drop(['time_window'], axis=1)\", 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'table = avg_travel_time_preprocess(avg_travel_ti..._travel_time_preprocess(test_avg_volume, weather)', 'from sklearn.metrics import make_scorer\\n\\ndef mea...oss = make_scorer(mean_absolute_percentage_error)', ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'Out': {4: ['.DS_Store', 'links (table 3).csv', 'routes (table 4).csv', 'trajectories(table 5)_training.csv', 'volume(table 6)_training.csv', 'weather (table 7)_training.csv', 'scripts', '__MACOSX', 'training_20min_avg_travel_time.csv', 'training_20min_avg_volume.csv', 'A2.csv', 'A3.csv', 'B1.csv', 'B3.csv', 'C1.csv', 'C3.csv', 'test1_20min_avg_volume.csv', 'test1_20min_avg_travel_time.csv'], 9:   intersection_id  tollgate_id  avg_travel_time ... \n3 2016-07-19 02:20:00  \n4 2016-07-19 03:00:00  , 10:      intersection_id  tollgate_id  avg_travel_ti... 2016-07-19 05:00:00  \n4807 2016-07-19 05:40:00  , 20: '\\nfrom sklearn.feature_selection import SelectFro...x = selector.fit_transform(X=train_x, y=train_y)\\n', 21: 0.32361023627100327, 22: 0.10403991227510721, 24: 0.28154877806306217, 25: 0.2161926385969567, 26: 0.3156539591681151, 27: 0.10499420405033072, ...}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': {'mean_fit_time': array([ 0.3389349 ,  0.65601699,  2.88328171,  0.30546602,  0.59187984,\n        2.5291241 ]), 'mean_score_time': array([ 0.00948834,  0.01910043,  0.07291818,  0.00884191,  0.01568969,\n        0.06556018]), 'mean_test_score': array([ 0.36879043,  0.37023977,  0.35985518,  0.37424282,  0.36377716,\n        0.35553236]), 'mean_train_score': array([ 0.10472752,  0.1003971 ,  0.09579037,  0.12959896,  0.12456811,\n        0.12030286]), 'param_min_samples_split': masked_array(data = [2 2 2 3 3 3],\n             ...False False False False],\n       fill_value = ?)\n, 'param_n_estimators': masked_array(data = [10 20 100 10 20 100],\n     ...False False False False],\n       fill_value = ?)\n, 'params': ({'min_samples_split': 2, 'n_estimators': 10}, {'min_samples_split': 2, 'n_estimators': 20}, {'min_samples_split': 2, 'n_estimators': 100}, {'min_samples_split': 3, 'n_estimators': 10}, {'min_samples_split': 3, 'n_estimators': 20}, {'min_samples_split': 3, 'n_estimators': 100}), 'rank_test_score': array([3, 2, 5, 1, 4, 6], dtype=int32), 'split0_test_score': array([ 0.31195755,  0.30907785,  0.30914222,  0.31489928,  0.30741316,\n        0.30619604]), 'split0_train_score': array([ 0.10249962,  0.09804623,  0.09360308,  0.12576325,  0.12181913,\n        0.11750645]), ...}, '_10':      intersection_id  tollgate_id  avg_travel_ti... 2016-07-19 05:00:00  \n4807 2016-07-19 05:40:00  , '_100': {'n_estimators': 100}, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HTML': <class 'IPython.core.display.HTML'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport sklearn as sk', 'import os\\nfrom matplotlib import pyplot as plt\\nimport seaborn as sbn', \"get_ipython().magic('matplotlib inline')\\nplt.style.use('seaborn-paper')\", \"os.listdir('..')\", \"data = {\\n    'links': pd.read_csv('../links (tab...avg_travel_time']\\navg_volume = data['avg_volume']\", 'from IPython.display import display, HTML\\n\\nfor t...\\n    print(table_name)\\n    display(table.head(5))', 'def split_time_window(time_window):\\n    time_sta...time_start)), pd.to_datetime(pd.Series(time_end))', \"avg_travel_time['time_start'], avg_travel_time['...volume = avg_volume.drop(['time_window'], axis=1)\", 'avg_travel_time.head()', \"avg_travel_time[avg_travel_time.intersection_id == 'A'].head()\", \"# Time Seq\\ndef get_avg_time(intersection_id, tol...tart','avg_travel_time']].set_index('time_start')\", \"names = ['A', 'B', 'C']\\ntollgates = [1, 2, 3]\\n\\nf... seq.to_csv('../{}{}.csv'.format(name, tollgate))\", 'def handleTime(time):\\n    return pd.DataFrame({\\n...ute\": pd.Series([t.minute for t in time]),\\n    })', \"test_avg_volume = pd.read_csv('../test1_20min_av...e = test_avg_volume.drop(['time_window'], axis=1)\", 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'table = avg_travel_time_preprocess(avg_travel_ti..._travel_time_preprocess(test_avg_volume, weather)', 'from sklearn.metrics import make_scorer\\n\\ndef mea...oss = make_scorer(mean_absolute_percentage_error)', ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'Out': {4: ['.DS_Store', 'links (table 3).csv', 'routes (table 4).csv', 'trajectories(table 5)_training.csv', 'volume(table 6)_training.csv', 'weather (table 7)_training.csv', 'scripts', '__MACOSX', 'training_20min_avg_travel_time.csv', 'training_20min_avg_volume.csv', 'A2.csv', 'A3.csv', 'B1.csv', 'B3.csv', 'C1.csv', 'C3.csv', 'test1_20min_avg_volume.csv', 'test1_20min_avg_travel_time.csv'], 9:   intersection_id  tollgate_id  avg_travel_time ... \n3 2016-07-19 02:20:00  \n4 2016-07-19 03:00:00  , 10:      intersection_id  tollgate_id  avg_travel_ti... 2016-07-19 05:00:00  \n4807 2016-07-19 05:40:00  , 20: '\\nfrom sklearn.feature_selection import SelectFro...x = selector.fit_transform(X=train_x, y=train_y)\\n', 21: 0.32361023627100327, 22: 0.10403991227510721, 24: 0.28154877806306217, 25: 0.2161926385969567, 26: 0.3156539591681151, 27: 0.10499420405033072, ...}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': {'mean_fit_time': array([ 0.3389349 ,  0.65601699,  2.88328171,  0.30546602,  0.59187984,\n        2.5291241 ]), 'mean_score_time': array([ 0.00948834,  0.01910043,  0.07291818,  0.00884191,  0.01568969,\n        0.06556018]), 'mean_test_score': array([ 0.36879043,  0.37023977,  0.35985518,  0.37424282,  0.36377716,\n        0.35553236]), 'mean_train_score': array([ 0.10472752,  0.1003971 ,  0.09579037,  0.12959896,  0.12456811,\n        0.12030286]), 'param_min_samples_split': masked_array(data = [2 2 2 3 3 3],\n             ...False False False False],\n       fill_value = ?)\n, 'param_n_estimators': masked_array(data = [10 20 100 10 20 100],\n     ...False False False False],\n       fill_value = ?)\n, 'params': ({'min_samples_split': 2, 'n_estimators': 10}, {'min_samples_split': 2, 'n_estimators': 20}, {'min_samples_split': 2, 'n_estimators': 100}, {'min_samples_split': 3, 'n_estimators': 10}, {'min_samples_split': 3, 'n_estimators': 20}, {'min_samples_split': 3, 'n_estimators': 100}), 'rank_test_score': array([3, 2, 5, 1, 4, 6], dtype=int32), 'split0_test_score': array([ 0.31195755,  0.30907785,  0.30914222,  0.31489928,  0.30741316,\n        0.30619604]), 'split0_train_score': array([ 0.10249962,  0.09804623,  0.09360308,  0.12576325,  0.12181913,\n        0.11750645]), ...}, '_10':      intersection_id  tollgate_id  avg_travel_ti... 2016-07-19 05:00:00  \n4807 2016-07-19 05:40:00  , '_100': {'n_estimators': 100}, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/yecheng/Documents/KDD/dataSets/training/scripts/<ipython-input-117-0c68ea15d7d3> in <module>()\n     28     'n_estimators':(10, 20, 100),\n     29     'min_samples_split':(2,3),\n     30 }\n     31 \n     32 model = GridSearchCV(model, parameters, scoring=loss, n_jobs=-1)\n---> 33 model.fit(train_x, train_y)\n     34 \n     35 model.best_params_\n     36 \n     37 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...corer(mean_absolute_percentage_error), verbose=0), X=       intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], y=0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...orer(mean_absolute_percentage_error), verbose=0)>\n        X =        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns]\n        y = 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64\n        groups = None\n        self.param_grid = {'min_samples_split': (2, 3), 'n_estimators': (10, 20, 100)}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...corer(mean_absolute_percentage_error), verbose=0), X=       intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], y=0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Apr  4 16:28:49 2017\nPID: 27944                 Python 3.5.2: /home/yecheng/anaconda3/bin/python\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None),        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, make_scorer(mean_absolute_percentage_error), array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), array([   0,    1,    2, ..., 8379, 8380, 8381]), 0, {'min_samples_split': 2, 'n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None),        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, make_scorer(mean_absolute_percentage_error), array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), array([   0,    1,    2, ..., 8379, 8380, 8381]), 0, {'min_samples_split': 2, 'n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None), X=       intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], y=0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, scorer=make_scorer(mean_absolute_percentage_error), train=array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), test=array([   0,    1,    2, ..., 8379, 8380, 8381]), verbose=0, parameters={'min_samples_split': 2, 'n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseEstimator.set_params of AdaBoo...r',\n         n_estimators=50, random_state=None)>\n        parameters = {'min_samples_split': 2, 'n_estimators': 10}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/base.py in set_params(self=AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None), **params={'min_samples_split': 2, 'n_estimators': 10})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'min_samples_split'\n        self.__class__.__name__ = 'AdaBoostRegressor'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter min_samples_split for estimator AdaBoostRegressor. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 227, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/base.py\", line 291, in set_params\n    (key, self.__class__.__name__))\nValueError: Invalid parameter min_samples_split for estimator AdaBoostRegressor. Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/yecheng/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Apr  4 16:28:49 2017\nPID: 27944                 Python 3.5.2: /home/yecheng/anaconda3/bin/python\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None),        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, make_scorer(mean_absolute_percentage_error), array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), array([   0,    1,    2, ..., 8379, 8380, 8381]), 0, {'min_samples_split': 2, 'n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None),        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, make_scorer(mean_absolute_percentage_error), array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), array([   0,    1,    2, ..., 8379, 8380, 8381]), 0, {'min_samples_split': 2, 'n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None), X=       intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], y=0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, scorer=make_scorer(mean_absolute_percentage_error), train=array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), test=array([   0,    1,    2, ..., 8379, 8380, 8381]), verbose=0, parameters={'min_samples_split': 2, 'n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseEstimator.set_params of AdaBoo...r',\n         n_estimators=50, random_state=None)>\n        parameters = {'min_samples_split': 2, 'n_estimators': 10}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/base.py in set_params(self=AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None), **params={'min_samples_split': 2, 'n_estimators': 10})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'min_samples_split'\n        self.__class__.__name__ = 'AdaBoostRegressor'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter min_samples_split for estimator AdaBoostRegressor. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Apr  4 16:28:49 2017\nPID: 27944                 Python 3.5.2: /home/yecheng/anaconda3/bin/python\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None),        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, make_scorer(mean_absolute_percentage_error), array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), array([   0,    1,    2, ..., 8379, 8380, 8381]), 0, {'min_samples_split': 2, 'n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None),        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, make_scorer(mean_absolute_percentage_error), array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), array([   0,    1,    2, ..., 8379, 8380, 8381]), 0, {'min_samples_split': 2, 'n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None), X=       intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], y=0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, scorer=make_scorer(mean_absolute_percentage_error), train=array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), test=array([   0,    1,    2, ..., 8379, 8380, 8381]), verbose=0, parameters={'min_samples_split': 2, 'n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseEstimator.set_params of AdaBoo...r',\n         n_estimators=50, random_state=None)>\n        parameters = {'min_samples_split': 2, 'n_estimators': 10}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/base.py in set_params(self=AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None), **params={'min_samples_split': 2, 'n_estimators': 10})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'min_samples_split'\n        self.__class__.__name__ = 'AdaBoostRegressor'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter min_samples_split for estimator AdaBoostRegressor. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-0c68ea15d7d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f3ee3b2fae0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/yechen.../python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f3ee3b2fae0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/yechen.../python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    648 \n    649         If a global instance already exists, this reinitializes and starts it\n    650         \"\"\"\n    651         app = cls.instance(**kwargs)\n    652         app.initialize(argv)\n--> 653         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    654 \n    655 #-----------------------------------------------------------------------------\n    656 # utility functions, for convenience\n    657 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-04-04T16:28:49.376575', 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'session': '81B9D28FBEA24355AFCFC9A0F904F383', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'81B9D28FBEA24355AFCFC9A0F904F383']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-04-04T16:28:49.376575', 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'session': '81B9D28FBEA24355AFCFC9A0F904F383', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'81B9D28FBEA24355AFCFC9A0F904F383'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-04-04T16:28:49.376575', 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'session': '81B9D28FBEA24355AFCFC9A0F904F383', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C57F0F24D7E845ADBD0AC1FF8082FF30', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='import xgboost as xgb\\nfrom sklearn.ensemble impo...)\\nmodel.fit(train_x, train_y)\\n\\nmodel.best_params_', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-117-0c68ea15d7d3>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f3e7bf0dcf8, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3ea5712390, file \"<ipython-input-117-0c68ea15d7d3>\", line 33>\n        result = <ExecutionResult object at 7f3e7bf0dcf8, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3ea5712390, file \"<ipython-input-117-0c68ea15d7d3>\", line 33>, result=<ExecutionResult object at 7f3e7bf0dcf8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3ea5712390, file \"<ipython-input-117-0c68ea15d7d3>\", line 33>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HTML': <class 'IPython.core.display.HTML'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport sklearn as sk', 'import os\\nfrom matplotlib import pyplot as plt\\nimport seaborn as sbn', \"get_ipython().magic('matplotlib inline')\\nplt.style.use('seaborn-paper')\", \"os.listdir('..')\", \"data = {\\n    'links': pd.read_csv('../links (tab...avg_travel_time']\\navg_volume = data['avg_volume']\", 'from IPython.display import display, HTML\\n\\nfor t...\\n    print(table_name)\\n    display(table.head(5))', 'def split_time_window(time_window):\\n    time_sta...time_start)), pd.to_datetime(pd.Series(time_end))', \"avg_travel_time['time_start'], avg_travel_time['...volume = avg_volume.drop(['time_window'], axis=1)\", 'avg_travel_time.head()', \"avg_travel_time[avg_travel_time.intersection_id == 'A'].head()\", \"# Time Seq\\ndef get_avg_time(intersection_id, tol...tart','avg_travel_time']].set_index('time_start')\", \"names = ['A', 'B', 'C']\\ntollgates = [1, 2, 3]\\n\\nf... seq.to_csv('../{}{}.csv'.format(name, tollgate))\", 'def handleTime(time):\\n    return pd.DataFrame({\\n...ute\": pd.Series([t.minute for t in time]),\\n    })', \"test_avg_volume = pd.read_csv('../test1_20min_av...e = test_avg_volume.drop(['time_window'], axis=1)\", 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'table = avg_travel_time_preprocess(avg_travel_ti..._travel_time_preprocess(test_avg_volume, weather)', 'from sklearn.metrics import make_scorer\\n\\ndef mea...oss = make_scorer(mean_absolute_percentage_error)', ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'Out': {4: ['.DS_Store', 'links (table 3).csv', 'routes (table 4).csv', 'trajectories(table 5)_training.csv', 'volume(table 6)_training.csv', 'weather (table 7)_training.csv', 'scripts', '__MACOSX', 'training_20min_avg_travel_time.csv', 'training_20min_avg_volume.csv', 'A2.csv', 'A3.csv', 'B1.csv', 'B3.csv', 'C1.csv', 'C3.csv', 'test1_20min_avg_volume.csv', 'test1_20min_avg_travel_time.csv'], 9:   intersection_id  tollgate_id  avg_travel_time ... \n3 2016-07-19 02:20:00  \n4 2016-07-19 03:00:00  , 10:      intersection_id  tollgate_id  avg_travel_ti... 2016-07-19 05:00:00  \n4807 2016-07-19 05:40:00  , 20: '\\nfrom sklearn.feature_selection import SelectFro...x = selector.fit_transform(X=train_x, y=train_y)\\n', 21: 0.32361023627100327, 22: 0.10403991227510721, 24: 0.28154877806306217, 25: 0.2161926385969567, 26: 0.3156539591681151, 27: 0.10499420405033072, ...}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': {'mean_fit_time': array([ 0.3389349 ,  0.65601699,  2.88328171,  0.30546602,  0.59187984,\n        2.5291241 ]), 'mean_score_time': array([ 0.00948834,  0.01910043,  0.07291818,  0.00884191,  0.01568969,\n        0.06556018]), 'mean_test_score': array([ 0.36879043,  0.37023977,  0.35985518,  0.37424282,  0.36377716,\n        0.35553236]), 'mean_train_score': array([ 0.10472752,  0.1003971 ,  0.09579037,  0.12959896,  0.12456811,\n        0.12030286]), 'param_min_samples_split': masked_array(data = [2 2 2 3 3 3],\n             ...False False False False],\n       fill_value = ?)\n, 'param_n_estimators': masked_array(data = [10 20 100 10 20 100],\n     ...False False False False],\n       fill_value = ?)\n, 'params': ({'min_samples_split': 2, 'n_estimators': 10}, {'min_samples_split': 2, 'n_estimators': 20}, {'min_samples_split': 2, 'n_estimators': 100}, {'min_samples_split': 3, 'n_estimators': 10}, {'min_samples_split': 3, 'n_estimators': 20}, {'min_samples_split': 3, 'n_estimators': 100}), 'rank_test_score': array([3, 2, 5, 1, 4, 6], dtype=int32), 'split0_test_score': array([ 0.31195755,  0.30907785,  0.30914222,  0.31489928,  0.30741316,\n        0.30619604]), 'split0_train_score': array([ 0.10249962,  0.09804623,  0.09360308,  0.12576325,  0.12181913,\n        0.11750645]), ...}, '_10':      intersection_id  tollgate_id  avg_travel_ti... 2016-07-19 05:00:00  \n4807 2016-07-19 05:40:00  , '_100': {'n_estimators': 100}, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HTML': <class 'IPython.core.display.HTML'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport sklearn as sk', 'import os\\nfrom matplotlib import pyplot as plt\\nimport seaborn as sbn', \"get_ipython().magic('matplotlib inline')\\nplt.style.use('seaborn-paper')\", \"os.listdir('..')\", \"data = {\\n    'links': pd.read_csv('../links (tab...avg_travel_time']\\navg_volume = data['avg_volume']\", 'from IPython.display import display, HTML\\n\\nfor t...\\n    print(table_name)\\n    display(table.head(5))', 'def split_time_window(time_window):\\n    time_sta...time_start)), pd.to_datetime(pd.Series(time_end))', \"avg_travel_time['time_start'], avg_travel_time['...volume = avg_volume.drop(['time_window'], axis=1)\", 'avg_travel_time.head()', \"avg_travel_time[avg_travel_time.intersection_id == 'A'].head()\", \"# Time Seq\\ndef get_avg_time(intersection_id, tol...tart','avg_travel_time']].set_index('time_start')\", \"names = ['A', 'B', 'C']\\ntollgates = [1, 2, 3]\\n\\nf... seq.to_csv('../{}{}.csv'.format(name, tollgate))\", 'def handleTime(time):\\n    return pd.DataFrame({\\n...ute\": pd.Series([t.minute for t in time]),\\n    })', \"test_avg_volume = pd.read_csv('../test1_20min_av...e = test_avg_volume.drop(['time_window'], axis=1)\", 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'from sklearn.preprocessing import LabelEncoder\\nd...ansform(y=table.intersection_id)\\n    return table', 'table = avg_travel_time_preprocess(avg_travel_ti..._travel_time_preprocess(test_avg_volume, weather)', 'from sklearn.metrics import make_scorer\\n\\ndef mea...oss = make_scorer(mean_absolute_percentage_error)', ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'Out': {4: ['.DS_Store', 'links (table 3).csv', 'routes (table 4).csv', 'trajectories(table 5)_training.csv', 'volume(table 6)_training.csv', 'weather (table 7)_training.csv', 'scripts', '__MACOSX', 'training_20min_avg_travel_time.csv', 'training_20min_avg_volume.csv', 'A2.csv', 'A3.csv', 'B1.csv', 'B3.csv', 'C1.csv', 'C3.csv', 'test1_20min_avg_volume.csv', 'test1_20min_avg_travel_time.csv'], 9:   intersection_id  tollgate_id  avg_travel_time ... \n3 2016-07-19 02:20:00  \n4 2016-07-19 03:00:00  , 10:      intersection_id  tollgate_id  avg_travel_ti... 2016-07-19 05:00:00  \n4807 2016-07-19 05:40:00  , 20: '\\nfrom sklearn.feature_selection import SelectFro...x = selector.fit_transform(X=train_x, y=train_y)\\n', 21: 0.32361023627100327, 22: 0.10403991227510721, 24: 0.28154877806306217, 25: 0.2161926385969567, 26: 0.3156539591681151, 27: 0.10499420405033072, ...}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': {'mean_fit_time': array([ 0.3389349 ,  0.65601699,  2.88328171,  0.30546602,  0.59187984,\n        2.5291241 ]), 'mean_score_time': array([ 0.00948834,  0.01910043,  0.07291818,  0.00884191,  0.01568969,\n        0.06556018]), 'mean_test_score': array([ 0.36879043,  0.37023977,  0.35985518,  0.37424282,  0.36377716,\n        0.35553236]), 'mean_train_score': array([ 0.10472752,  0.1003971 ,  0.09579037,  0.12959896,  0.12456811,\n        0.12030286]), 'param_min_samples_split': masked_array(data = [2 2 2 3 3 3],\n             ...False False False False],\n       fill_value = ?)\n, 'param_n_estimators': masked_array(data = [10 20 100 10 20 100],\n     ...False False False False],\n       fill_value = ?)\n, 'params': ({'min_samples_split': 2, 'n_estimators': 10}, {'min_samples_split': 2, 'n_estimators': 20}, {'min_samples_split': 2, 'n_estimators': 100}, {'min_samples_split': 3, 'n_estimators': 10}, {'min_samples_split': 3, 'n_estimators': 20}, {'min_samples_split': 3, 'n_estimators': 100}), 'rank_test_score': array([3, 2, 5, 1, 4, 6], dtype=int32), 'split0_test_score': array([ 0.31195755,  0.30907785,  0.30914222,  0.31489928,  0.30741316,\n        0.30619604]), 'split0_train_score': array([ 0.10249962,  0.09804623,  0.09360308,  0.12576325,  0.12181913,\n        0.11750645]), ...}, '_10':      intersection_id  tollgate_id  avg_travel_ti... 2016-07-19 05:00:00  \n4807 2016-07-19 05:40:00  , '_100': {'n_estimators': 100}, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/yecheng/Documents/KDD/dataSets/training/scripts/<ipython-input-117-0c68ea15d7d3> in <module>()\n     28     'n_estimators':(10, 20, 100),\n     29     'min_samples_split':(2,3),\n     30 }\n     31 \n     32 model = GridSearchCV(model, parameters, scoring=loss, n_jobs=-1)\n---> 33 model.fit(train_x, train_y)\n     34 \n     35 model.best_params_\n     36 \n     37 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...corer(mean_absolute_percentage_error), verbose=0), X=       intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], y=0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...orer(mean_absolute_percentage_error), verbose=0)>\n        X =        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns]\n        y = 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64\n        groups = None\n        self.param_grid = {'min_samples_split': (2, 3), 'n_estimators': (10, 20, 100)}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...corer(mean_absolute_percentage_error), verbose=0), X=       intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], y=0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Apr  4 16:28:49 2017\nPID: 27944                 Python 3.5.2: /home/yecheng/anaconda3/bin/python\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None),        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, make_scorer(mean_absolute_percentage_error), array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), array([   0,    1,    2, ..., 8379, 8380, 8381]), 0, {'min_samples_split': 2, 'n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None),        intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], 0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, make_scorer(mean_absolute_percentage_error), array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), array([   0,    1,    2, ..., 8379, 8380, 8381]), 0, {'min_samples_split': 2, 'n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None), X=       intersection_id  tollgate_id  day_in_mont...    22      40     10  \n\n[25144 rows x 8 columns], y=0         70.85\n1        148.79\n2         93.72\n...3    150.53\nName: avg_travel_time, dtype: float64, scorer=make_scorer(mean_absolute_percentage_error), train=array([ 8382,  8383,  8384, ..., 25141, 25142, 25143]), test=array([   0,    1,    2, ..., 8379, 8380, 8381]), verbose=0, parameters={'min_samples_split': 2, 'n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseEstimator.set_params of AdaBoo...r',\n         n_estimators=50, random_state=None)>\n        parameters = {'min_samples_split': 2, 'n_estimators': 10}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/base.py in set_params(self=AdaBoostRegressor(base_estimator=None, learning_...ar',\n         n_estimators=50, random_state=None), **params={'min_samples_split': 2, 'n_estimators': 10})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'min_samples_split'\n        self.__class__.__name__ = 'AdaBoostRegressor'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter min_samples_split for estimator AdaBoostRegressor. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# model = xgb.XGBRegressor(max_depth=5,\n",
    "#                          learning_rate=0.1,\n",
    "#                          n_estimators=400,\n",
    "#                          silent=False, \n",
    "#                          objective='reg:linear', \n",
    "#                          gamma=0, \n",
    "#                          min_child_weight=1, \n",
    "#                          max_delta_step=0, \n",
    "#                          subsample=1, \n",
    "#                          colsample_bytree=1, \n",
    "#                          colsample_bylevel=1, \n",
    "#                          reg_alpha=0, \n",
    "#                          reg_lambda=1, \n",
    "#                          base_score=0.5, \n",
    "#                          seed=0, \n",
    "#                          missing=None)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model = model.fit(X=train_x, y=train_y)\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators':(10, 20, 100),\n",
    "    'min_samples_split':(2,3),\n",
    "}\n",
    "\n",
    "model = GridSearchCV(model, parameters, scoring=loss, n_jobs=-1)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-e16580ffc354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_check_is_fitted\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                   'parameters. ') % method_name)\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yecheng/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# FIXME NotFittedError_ --> NotFittedError in 0.19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_NotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_x)\n",
    "mean_absolute_percentage_error(train_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-eb84ec34633e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't2' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(t2, train_y)\n",
    "y_pred = model.predict(selector.transform(train_x))\n",
    "mean_absolute_percentage_error(train_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.3389349 ,  0.65601699,  2.88328171,  0.30546602,  0.59187984,\n",
       "         2.5291241 ]),\n",
       " 'mean_score_time': array([ 0.00948834,  0.01910043,  0.07291818,  0.00884191,  0.01568969,\n",
       "         0.06556018]),\n",
       " 'mean_test_score': array([ 0.36879043,  0.37023977,  0.35985518,  0.37424282,  0.36377716,\n",
       "         0.35553236]),\n",
       " 'mean_train_score': array([ 0.10472752,  0.1003971 ,  0.09579037,  0.12959896,  0.12456811,\n",
       "         0.12030286]),\n",
       " 'param_min_samples_split': masked_array(data = [2 2 2 3 3 3],\n",
       "              mask = [False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_estimators': masked_array(data = [10 20 100 10 20 100],\n",
       "              mask = [False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'min_samples_split': 2, 'n_estimators': 10},\n",
       "  {'min_samples_split': 2, 'n_estimators': 20},\n",
       "  {'min_samples_split': 2, 'n_estimators': 100},\n",
       "  {'min_samples_split': 3, 'n_estimators': 10},\n",
       "  {'min_samples_split': 3, 'n_estimators': 20},\n",
       "  {'min_samples_split': 3, 'n_estimators': 100}),\n",
       " 'rank_test_score': array([3, 2, 5, 1, 4, 6], dtype=int32),\n",
       " 'split0_test_score': array([ 0.31195755,  0.30907785,  0.30914222,  0.31489928,  0.30741316,\n",
       "         0.30619604]),\n",
       " 'split0_train_score': array([ 0.10249962,  0.09804623,  0.09360308,  0.12576325,  0.12181913,\n",
       "         0.11750645]),\n",
       " 'split1_test_score': array([ 0.47137028,  0.47250344,  0.4621427 ,  0.47432182,  0.45345571,\n",
       "         0.456094  ]),\n",
       " 'split1_train_score': array([ 0.10652503,  0.10266554,  0.09789046,  0.13281692,  0.12685386,\n",
       "         0.12267546]),\n",
       " 'split2_test_score': array([ 0.32305025,  0.32914533,  0.30828667,  0.33351445,  0.33046934,\n",
       "         0.30431293]),\n",
       " 'split2_train_score': array([ 0.10515791,  0.10047953,  0.09587758,  0.13021671,  0.12503135,\n",
       "         0.12072668]),\n",
       " 'std_fit_time': array([ 0.00760271,  0.01122029,  0.24947169,  0.00170308,  0.0042742 ,\n",
       "         0.23445375]),\n",
       " 'std_score_time': array([ 0.00058529,  0.00229139,  0.00628277,  0.00068284,  0.00119001,\n",
       "         0.00573448]),\n",
       " 'std_test_score': array([ 0.07267398,  0.0727718 ,  0.07232689,  0.07117134,  0.06410523,\n",
       "         0.07110985]),\n",
       " 'std_train_score': array([ 0.00167131,  0.00188673,  0.0017514 ,  0.00291259,  0.00208136,\n",
       "         0.00213141])}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
